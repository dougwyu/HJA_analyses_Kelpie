spp <- data.frame(species = colnames(Y.train.pa)) %>%
tidyr::separate(col = species, into = c("OTU", "empty", "class", "order", "family",
"genus", "epithet", "BOLD", "BOLDID",
"size"),
remove = FALSE, sep = "_") %>%
select(-empty)
head(spp)
# convert to NAs
for(c in seq_along(spp)[-1]) spp[,c] <- sub("NA", NA, spp[,c])
# Add dummy family and genus
spp$family[is.na(spp$family)] <- sprintf("fam%03d", 1:sum((is.na(spp$family))))
spp$genus[is.na(spp$genus)] <- sprintf("gen%03d", 1:sum((is.na(spp$genus))))
head(spp)
# convert to factors for ape
spp <- spp[order(spp$class, spp$order, spp$family, spp$genus),]
tax.cols <- c("class", "order", "family", "genus", "epithet", "species")
for(i in tax.cols) spp[,i] <- factor(spp[,i])
head(spp)
P <- ape::as.phylo(~class/order/family/genus/species, data = spp, collapse = F)
P$edge.length = rep(1, length(P$edge)) # make all lengths eqaul between tax levels
ape::is.rooted(P)
all(P$tip.label %in% colnames(Y.train.pa))
all(P$tip.label %in% colnames(Y.train.qp))
# save(Y.train.pa, Y.train.qp, X.train, S.train, P, file = "data/allData_vif.rdata")
rm(c, i, tax.cols, spp)
write.csv(env.vars, "Hsmc_CD/local/data/biodiversity_site_info_GIS_vars_20210115.csv", row.names = F)
write.csv(env.vars, "Hmsc_CD/local/data/biodiversity_site_info_GIS_vars_20210115.csv", row.names = F)
write.csv(env.vars, "HJA_scripts/10_eo_data/biodiversity_site_info_GIS_vars_20210115.csv", row.names = F)
devtools::install_github("https://github.com/TheoreticalEcology/s-jSDM", subdir = "sjSDM")
install.packages(c("glmnet", "htmltools", "MCMCpack", "pROC", "RcppArmadillo"))
devtools::install_github("https://github.com/TheoreticalEcology/s-jSDM", subdir = "sjSDM")
library(sJSDM)
library(sjSDM)
n
pack <- "sjSDM"
path <- find.package(pack)
system(paste(shQuote(file.path(R.home("bin"), "R")),"CMD", "Rd2pdf", shQuote(path)))
file.path(R.home("bin"), "R")
shQuote(file.path(R.home("bin"), "R")),"CMD", "Rd2pdf", shQuote(path)
shQuote(file.path(R.home("bin"), "R")),"CMD", "Rd2pdf", shQuote(path))
shQuote(file.path(R.home("bin"), "R")),"CMD", "Rd2pdf", shQuote(path)
shQuote(file.path(R.home("bin"), "R")),"CMD", "Rd2pdf", shQuote(path))
paste(shQuote(file.path(R.home("bin"), "R")),"CMD", "Rd2pdf", shQuote(path))
devtools::build_manual(path)
set.seed(42)
community <- simulate_SDM(sites = 100, species = 10, env = 3)
setwd("J:/UEA/gitHRepos/HJA_analyses_Kelpie/Hmsc_CD/oregon_ada")
source('J:/UEA/gitHRepos/HJA_analyses_Kelpie/Hmsc_CD/oregon_ada/code_sjSDM/S1_read_data.r', echo=TRUE)
Y <- as.matrix(otu.pa.csv)
raretaxa <- which(colSums(Y.train.pa > 0) < 10)
length(raretaxa)
Y.train.pa2 <- Y.train.pa[, -raretaxa] # reduced species
rm(raretaxa)
Y.train.pa_min10 <- Y.train.pa[, -raretaxa] # reduced species
raretaxa <- which(colSums(Y.train.pa > 0) < 10)
length(raretaxa)
Y.train.pa_min10 <- Y.train.pa[, -raretaxa] # reduced species
rm(raretaxa)
Y.train.pa_min10 <- as.matrix(Y.train.pa[, -raretaxa]) # reduced species
raretaxa <- which(colSums(Y.train.pa > 0) < 10)
length(raretaxa)
Y.train.pa_min10 <- as.matrix(Y.train.pa[, -raretaxa]) # reduced species
rm(raretaxa)
all(all.vars(XFormula1) %in% names(X.train))
XFormula1 <- as.formula(~be10+B11_median+mean.EVI+insideHJA + Ess + ht + ht.r500 + cov4_16 + cov4_16.r500 + mTopo)
all(all.vars(XFormula1) %in% names(X.train))
mm <- model.matrix(XFormula1, data = env.vars)
head(mm)
head(S.train)
load("J:/UEA/gitHRepos/HJA_analyses_Kelpie/Hmsc_CD/oregon_ada/code_sjSDM/sjSDM_trial/sjDM_trial_mods.rdata")
head(mm)
typeof(XFormula1)
str(X.train)
head(as.matrix(X.train))
form1 <- as.formula(~V1+V2+V3)
form1
class(form1)
form1 <- formula(~V1+V2+V3)
form1
class(form1)
match.call(form1)
mf <- match.call()
mf
match("formula", names(mf))
formula <- as.formula(~V1+V2+V3)
mf <- match.call()
match("formula", names(mf))
names(mf)
linear2 = function(data = NULL, formula = NULL, lambda = 0.0, alpha = 0.5) {
if(is.data.frame(data)) {
if(!is.null(formula)){
mf = match.call()
m = match("formula", names(mf))
formula = stats::as.formula(mf[m]$formula)
X = stats::model.matrix(formula, data)
} else {
formula = stats::as.formula("~.")
X = stats::model.matrix(formula, data)
}
form1 <- as.formula(~V1+V2+V3)
form1
linear2(data = Env, formula = form1)
community <- simulate_SDM(sites = 100, species = 10, env = 3)
form1 <- as.formula(~V1+V2+V3)
form1
Env <- data.frame(rnorm(25),rnorm(25),rnorm(25))
head(Env)
Env <- data.frame(V1 = rnorm(25), V2 = rnorm(25),V3 =rnorm(25))
head(Env)
linear2(data = Env, formula = form1)
mf = match.call()
formula = form1
if(!is.null(formula)){
mf = match.call()
m = match("formula", names(mf))
formula = stats::as.formula(mf[m]$formula)
X = stats::model.matrix(formula, data)
}
!is.null(formula)
data = Env
if(!is.null(formula)){
mf = match.call()
m = match("formula", names(mf))
formula = stats::as.formula(mf[m]$formula)
X = stats::model.matrix(formula, data)
}
!is.null(formula)
mf = match.call()
m = match("formula", names(mf))
formula = stats::as.formula(mf[m]$formula)
X = stats::model.matrix(formula, data)
community <- sjSDM::simulate_SDM(sites = 100, species = 10, env = 3)
community <- sjSDM::simulate_SDM(sites = 50, species = 10, env = 3)
community <- sjSDM::simulate_SDM(sites = 100, species = 10, env = 3)
Env <- community$env_weights
Occ <- community$response
SP <- matrix(rnorm(200, 0, 0.3), 100, 2) # spatial coordinates (no effect on species occurences)
# head(community)
head(Env)
head(Occ)
head(SP)
Env <- as.data.frame(Env)
linear(data = Env, formula = ~V1+V2+V3)
Env.lin <- sjSDM::linear(data = Env, formula = ~V1+V2+V3)
Env.lin
Env.lin1 <- sjSDM::linear(data = Env, formula = form1)
form1 <- as.formula(~V1+V2+V3)
form1
Env.lin1 <- sjSDM::linear(data = Env, formula = form1)
ls(envir = Env.lin2)
Env.lin2 <- sjSDM::linear(data = Env, formula = ~V1+V2+V3)
ls(envir = Env.lin2)
str(Env.lin2)
attr(Env.lin2$formula, ".Environment")
ls(envir = attr(Env.lin2$formula, ".Environment"))
library(sf)
options(sf_max.plot=1)
library(raster)
setwd("C:/Users/55116479/Dropbox (Manchester Met)/R_online/dbTapir")
load("pts_final.rdata")
set.seed(99)
bg <- dismo::randomPoints(stck.msk, 7500)
tmp <- extract(stck.msk[[1]], bg)
nrow(bg) - sum(complete.cases(tmp))
k <- 5
group <- dismo::kfold(st_coordinates(pts.p), k)
train <- sf::st_coordinates(pts.p)[group != i,]
test <- sf::st_coordinates(pts.p)[group == i,]
i = 1
train <- sf::st_coordinates(pts.p)[group != i,]
test <- sf::st_coordinates(pts.p)[group == i,]
mx <- dismo::maxent(x = stck.msk, p = train, a = bg)
str(mx)
predVals.pres <- predict(mx, mx@presence)
predVals.abs <- predict(mx, mx@absence)
p1 = mean(predVals.pres) # Mean predicted at pres.
p0 = mean(predVals.abs) # Mean predicted at background
d = p1-p0 # Calculate d for a given model
d
eval <- dismo::evaluate(p=test, a=bg, x=stck.msk, model = mx)
eval
str(eval)
eval@tjur <- d
evList <- as.list(eval)
head(pts.p)
sight.ab.av  <- rbind(st_coordinates(pts.p), bg)
sight.ab.av$pa <- c(rep(1, nrow(pts.p), rep(0, length(bg))))
sight.ab.av <- rbind(st_coordinates(pts.p), bg)
sight.ab.av$pa <- c(rep(1, nrow(pts.p)), rep(0, length(bg)))
nrow(pts.p)
length(bg)
sight.ab.av <- rbind(st_coordinates(pts.p), bg)
bg
st_coordinates(pts.p)
head(bg)
sight.ab.av <- rbind(st_coordinates(pts.p), bg)
sight.ab.av$pa <- c(rep(1, nrow(pts.p)), rep(0, nrow(bg)))
head(sight.ab.av)
nrow(pts.p)
nrow(bg)
sight.ab.av <- rbind(st_coordinates(pts.p), bg)
sight.ab.av <- data.frame(rbind(st_coordinates(pts.p), bg))
sight.ab.av$pa <- c(rep(1, nrow(pts.p)), rep(0, nrow(bg)))
head(sight.ab.av)
k <- 5
set.seed(99)
kfold <- dismo::kfold(sight.ab.av, k = k, by = pa)
kfold <- dismo::kfold(sight.ab.av, k = k, by = sight.ab.av$pa)
sight.ab.av <- data.frame(rbind(st_coordinates(pts.p), bg))
pa <- c(rep(1, nrow(pts.p)), rep(0, nrow(bg)))
head(sight.ab.av)
k <- 5
set.seed(99)
kfold <- dismo::kfold(sight.ab.av, k = k, by = pa)
table(kfold, pa)
mxRes <- list()
evRes <- list()
j = 1
trainData <- sight.ab.av[kfold != j,]
testData <- sight.ab.av[kfold == j,]
trainPA <- pa[kfold != j]
testPA <- pa[kfold == j]
mx <- dismo::maxent(x = trainData, p = trainPA, path = mxPath, removeDuplicates = TRUE)
mx <- dismo::maxent(x = trainData, p = trainPA, removeDuplicates = TRUE)
mxRes[[j]] <- mx
ev <- dismo::evaluate(p=testData[testPA == 1, ], a=testData[testPA == 0, ], model = mx)
ev
evRes[[j]] <- ev
predVals.pres <- predict(mx, mx@presence)
predVals.abs <- predict(mx, mx@absence)
p1 = mean(predVals.pres) # Mean predicted at pres.
p0 = mean(predVals.abs) # Mean predicted at background
d = p1-p0 # Calculate d for a given model
d
tjRes <- list()
for(j in 1:k){
# make training and test data
trainData <- sight.ab.av[kfold != j,]
testData <- sight.ab.av[kfold == j,]
# make training and test presence-absence info
trainPA <- pa[kfold != j]
testPA <- pa[kfold == j]
mx <- dismo::maxent(x = trainData, p = trainPA, removeDuplicates = TRUE)
mxRes[[j]] <- mx
#'evaluate'
ev <- dismo::evaluate(p=testData[testPA == 1, ], a=testData[testPA == 0, ], model = mx)
evRes[[j]] <- ev
predVals.pres <- predict(mx, mx@presence)
predVals.abs <- predict(mx, mx@absence)
p1 = mean(predVals.pres) # Mean predicted at pres.
p0 = mean(predVals.abs) # Mean predicted at background
d = p1-p0 # Calculate d for a given model
tjRes[[j]] <- d
# list(auc = eval@auc, tjur = d)
}
M2AUC<-sapply(evRes, function(x) mean(x@auc))
M2AUC
M2AUC <- sapply(evRes, function(x) x@auc)
M2AUC
sapply(tjRes, mean)
tjRes
unlist(tjRes)
mean(unlist(tjRes))
M2AUC <- sapply(evRes, function(x) x@auc)
M2AUC
getwd()
wd <- here::here()
setwd(wd)
dir()
rm(wd)
library(sf)
library(raster)
utm10N <- 32610
# EPSG:26910  NAD83 / UTM zone 10N
nadutm10 <- 26910
gis <- "J:/UEA/Oregon/gis"
dir(gis)
cov2_4 <- raster(file.path(gis, "r_utm", "lidar_metric_mosaic_Cover_2m_4m.tif"))
cov2_4
cov4_16 <- raster(file.path(gis, "r_utm", "lidar_metric_mosaic_Cover_4m_16m.tif"))
ht <- raster(file.path(gis, "r_utm", "lidar_metric_mosaic_p95.tif"))
ht
cut <- st_read(file.path(gis, "marie/disturbance.shp"))
cut
getwd()
wd <- here::here()
setwd(wd)
dir()
rm(wd)
library(sf)
library(raster)
# wgs84 UTM 10N
utm10N <- 32610
# EPSG:26910  NAD83 / UTM zone 10N
nadutm10 <- 26910
# EPSG:4269 # NAD 83
# nad83 <- 4269
gis <- "J:/UEA/Oregon/gis"
##
dir(gis)
# get points
# get data
source("Hmsc_CD/local/L1_read_data.r")
head(S.train)
xy.sf <- st_as_sf(S.train, coords = c("UTM_E", "UTM_N"), crs = nadutm10)
rm(S.train)
# transform to wgs utm to match rasters
xy.utm <- st_transform(xy.sf, crs = utm10N)
rm(xy.sf)
cut <- st_read(file.path(gis, "s_nad_utm/disturbance.shp"))
cut
cut[order(cut$YEAR, na.last = F),] # 0 shown in arcgis come in as NAs...
sum(is.na(cut$YEAR))
cut.utm <- st_transform(cut, crs = utm10N)
cut.utm
plot(cut.utm[, c("YEAR")])
plot(st_geometry(xy.utm), add = T, pch = 2, col = "black", cex = 1.5)
list.files(file.path(gis,"r_utm"), "lidar")
cov2_4 <- raster(file.path(gis, "r_utm", "lidar_metric_mosaic_Cover_2m_4m.tif"))
gis <- file.path(wd, "HJA_scripts/10_eo_data/raw_gis_data")
dir(gis)
gis <- file.path(wd, "HJA_scripts/10_eo_data/raw_gis_data") # pending some layers still, eg bareEarth.tif
getwd()
wd <- here::here()
setwd(wd)
dir()
gis <- file.path(wd, "HJA_scripts/10_eo_data/raw_gis_data") # pending some layers still, eg bareEarth.tif
dir(gis)
cut <- st_read(file.path(gis, "s_nad_utm/disturbance.shp"))
cut
cut[order(cut$YEAR, na.last = F),] # 0 shown in arcgis come in as NAs...
sum(is.na(cut$YEAR))
cut.utm <- st_transform(cut, crs = utm10N)
cut.utm
plot(cut.utm[, c("YEAR")])
plot(st_geometry(xy.utm), add = T, pch = 2, col = "black", cex = 1.5)
rm(cut)
list.files(file.path(gis,"r_utm"), "lidar")
cov2_4 <- raster(file.path(gis, "r_utm", "lidar_metric_mosaic_Cover_2m_4m.tif"))
cov4_16 <- raster(file.path(gis, "r_utm", "lidar_metric_mosaic_Cover_4m_16m.tif"))
ht <- raster(file.path(gis, "r_utm", "lidar_metric_mosaic_p95.tif"))
cov2_4
cov4_16
ht
hist(ht)
load("results_sjSDM/oregon_trial.rdata")
load("Hmsc_CD/oregon_ada/results_sjSDM/oregon_trial.rdata")
getwd()
load("Hmsc_CD/oregon_ada/results_sjSDM/oregon_trial.rdata")
str(model)
str(model, max.level = 1)
getwd() # should be /gpfs/home/hsp20azu/oregon_ada
samtoolsfilter = "F2308" # F2308 filter only
samtoolsqual = "q48"
minimaprundate = 20200929
kelpierundate = 20200927
primer = "BF3BR2"
minocc = 5
abund = 'qp' # pa , qp    # !!! change accordingly
trap <- "M1"; period = "S1"
date.model.run = 20210119   # !!! change accordingly
outputidxstatstabulatefolder = glue("outputs_minimap2_{minimaprundate}_{samtoolsfilter}_{samtoolsqual}_kelpie{kelpierundate}_{primer}_vsearch97")
outputpath = glue('../../Kelpie_maps/{outputidxstatstabulatefolder}')
library(glue)
library(dplyr)
outputidxstatstabulatefolder = glue("outputs_minimap2_{minimaprundate}_{samtoolsfilter}_{samtoolsqual}_kelpie{kelpierundate}_{primer}_vsearch97")
outputpath = glue('../../Kelpie_maps/{outputidxstatstabulatefolder}')
sjsdmV = '0.1.3.9000' # package version
# names for graph
sjsdmVfolder = glue('sjsdm-{sjsdmV}')
# ..... load data ......
alldata = read.csv(here(outputpath, glue('sample_by_species_table_{samtoolsfilter}_minimap2_{minimaprundate}_kelpie{kelpierundate}_FSL_qp.csv')), header=T, sep=',', stringsAsFactors = F, na.strings='NA')
wd <- getwd()
wd
alldata = read.csv(here(outputpath, glue('sample_by_species_table_{samtoolsfilter}_minimap2_{minimaprundate}_kelpie{kelpierundate}_FSL_qp.csv')), header=T, sep=',', stringsAsFactors = F, na.strings='NA')
outputpath = glue('Kelpie_maps/{outputidxstatstabulatefolder}')
alldata = read.csv(outputpath, glue('sample_by_species_table_{samtoolsfilter}_minimap2_{minimaprundate}_kelpie{kelpierundate}_FSL_qp.csv'), header=T, sep=',', stringsAsFactors = F, na.strings='NA')
file.path(outputpath, glue('sample_by_species_table_{samtoolsfilter}_minimap2_{minimaprundate}_kelpie{kelpierundate}_FSL_qp.csv')
)
alldata = read.csv(file.path(outputpath, glue('sample_by_species_table_{samtoolsfilter}_minimap2_{minimaprundate}_kelpie{kelpierundate}_FSL_qp.csv')), header=T, sep=',', stringsAsFactors = F, na.strings='NA')
dim(alldata)
names(alldata)[1:10]
load("Hmsc_CD/oregon_ada/data/demStats.rdata")
str(dem_stats)
trap; period
alldata1 = subset(alldata, trap == 'M1' & period == 'S1')
dim(alldata1)
names(alldata1)[102:103]
a = alldata1 %>% dplyr::select(contains('__'))
a = a[,which(specnumber(a, MARGIN=2)>=minocc)]
a = a[,which(vegan::specnumber(a, MARGIN=2)>=minocc)]
a = alldata1 %>% dplyr::select(contains('__'))
a = a[,which(vegan::specnumber(a, MARGIN=2)>=minocc)]
dim(a)
alldata1 = cbind(dplyr::select(alldata1, -contains('__')), a)
dim(alldata1)
num.sample = dim(a)[1]
select.percent = .8
ssdd = 100 		# please keep this value to make results comparable!
set.seed(ssdd)
a = base::sample(1:num.sample, round(num.sample*select.percent))
num.sample
num.sample*select.percent
otu = dplyr::select(alldata1, contains('__'))
otu.train = otu[a,]
dim(otu.train)
otu.test = otu[-a,]
envnames = c("insideHJA", "elevation_m", "canopyHeight_m", "minT_annual", "precipitation_mm", "distToRoad_m", "distToStream_m", "YrsSinceDist", "B1_20180717", "B2_20180717", "B3_20180717", "B4_20180717", "B5_20180717", "B6_20180717", "B7_20180717", "B10_20180717", "B11_20180717", "NDVI_20180717", "EVI_20180717", "B_20180717", "G_20180717", "W_20180717", "l_Cover_2m_max", "l_Cover_2m_4m", "l_Cover_4m_16m", "l_p25", "l_p95", "l_rumple")
ori.env = dplyr::select(left_join(dplyr::select(alldata1, envnames, "SiteName"), dplyr::select(dem_stats, 'SiteName', 'tri.pt'), by=c('SiteName'='SiteName')), -'SiteName')
# add 'roughness' -> tri.pt
ori.env.train = ori.env[a,]
ori.env.test = ori.env[-a,]
str(ori.env.test)
ori.XY = dplyr::select(alldata1, starts_with('UTM'))
ori.XY.train = ori.XY[a,]
ori.XY.test = ori.XY[-a,]
str(ori.XY.train)
# ... view data ...
par(mfrow=c(1,2))
hist(ori.env.train$elevation_m)
hist(ori.env$elevation_m)
ggplot(ori.XY, aes(UTM_E, UTM_N)) + geom_point() + geom_point(data=ori.XY.train, aes(colour='red')) + scale_colour_manual(labels = c('training'), values = c("red"))
library(ggplot2)
ggplot(ori.XY, aes(UTM_E, UTM_N)) + geom_point() + geom_point(data=ori.XY.train, aes(colour='red')) + scale_colour_manual(labels = c('training'), values = c("red"))
if (abund == 'pa')
{
otu.train = as.data.frame((otu.train>0)*1)
otu.test = as.data.frame((otu.test>0)*1)
}
# .. env data
scale.env.train.all = dplyr::select(ori.env.train, -'insideHJA') %>% scale()
str(scale.env.train.all)
scale.env.train = data.frame(scale.env.train.all) %>% add_column(insideHJA=as.factor(ori.env.train$insideHJA), .before=names(ori.env.train)[2])
??add_column
scale.env.train = data.frame(scale.env.train.all) %>% tibble::add_column(insideHJA=as.factor(ori.env.train$insideHJA), .before=names(ori.env.train)[2])
str(scale.env.train)
dd.env.scaler = data.frame(t(data.frame(env.mean = attr(scale.env.train.all, "scaled:center"), env.sd = attr(scale.env.train.all, "scaled:scale"))))
str(dd.env.scaler)
rm(scale.env.train.all)
scale.env.test = as.data.frame(do.call(rbind, apply(dplyr::select(ori.env.test, -'insideHJA'), 1, function(x){(x-dd.env.scaler['env.mean',])/dd.env.scaler['env.sd',]} ) )) %>% add_column(insideHJA=as.factor(ori.env.test$insideHJA), .before=names(ori.env.test)[2])
scale.env.test = as.data.frame(do.call(rbind, apply(dplyr::select(ori.env.test, -'insideHJA'), 1, function(x){(x-dd.env.scaler['env.mean',])/dd.env.scaler['env.sd',]} ) )) %>% tibble::add_column(insideHJA=as.factor(ori.env.test$insideHJA), .before=names(ori.env.test)[2])
str(scale.env.test)
XY.train.all = scale(ori.XY.train)
str(XY.train.all)
XY.train = data.frame(XY.train.all)
str(XY.train)
dd.xy.scaler = data.frame(t(data.frame(sp.mean = attr(XY.train.all, "scaled:center"), sp.sd = attr(XY.train.all, "scaled:scale"))))
str(dd.xy.scaler)
base::rownames(dd.xy.scaler)
rm(XY.train.all)
XY.test = as.data.frame(do.call(rbind, apply(ori.XY.test, 1, function(x){(x-dd.xy.scaler['sp.mean',])/dd.xy.scaler['sp.sd',]} ) ))
str(XY.test)
# ... view data ...
par(mfrow=c(2,2))
hist(ori.env.train[,2],xlim=c(1000,5500), breaks = 10)
hist(ori.env.test[,2],xlim=c(1000,5500), breaks = 10)
hist(scale(ori.env.test[,2]))
hist(scale.env.test[,2])
par(mfrow=c(1,2))
hist(XY.test[,2])
hist(XY.train[,2])
rm(dd.env.scaler, dd.xy.scaler)
s.otu.train = as.matrix(otu.train)
attr(s.otu.train, 'dimnames') = NULL
str(s.otu.train)
# set variables
formula.env = 'envDNN'
lambda.env = .1
alpha.env = .5
lambda.sp = .1
alpha.sp = .9
hidden = c(50L,50L,10L)
acti.sp = 'relu'
drop = .3
save(s.otu.train,scale.env.train, XY.train,  s.otu.test, scale.env.test, XY.test, file = "Hmsc_CD/oregon_ada/data/yuanghen_mod_data.rdata")
s.otu.test = as.matrix(otu.test)
attr(s.otu.test, 'dimnames') = NULL
str(s.otu.test)
save(s.otu.train,scale.env.train, XY.train,  s.otu.test, scale.env.test, XY.test, file = "Hmsc_CD/oregon_ada/data/yuanghen_mod_data.rdata")
setwd("J:/UEA/gitHRepos/HJA_analyses_Kelpie/Hmsc_CD/oregon_ada")
load("data/yuanghen_mod_data.rdata")
setwd("J:/UEA/gitHRepos/HJA_analyses_Kelpie/Hmsc_CD/oregon_ada")
source("code_sjSDM/S1_read_data.r")
raretaxa <- which(colSums(Y.train.pa > 0) < 10)
length(raretaxa)
Y.train.pa_min10 <- as.matrix(Y.train.pa[, -raretaxa]) # reduced species
rm(raretaxa)
XFormula1 <- as.formula(~be10+B11_median+mean.EVI+insideHJA + Ess + ht + ht.r500 + cov4_16 + cov4_16.r500 + mTopo)
# check names
all(all.vars(XFormula1) %in% names(X.train))
str(X.train)
raretaxa <- which(colSums(Y.train.pa > 0) < 10)
length(raretaxa)
Y.train.pa_min10 <- as.matrix(Y.train.pa[, -raretaxa]) # reduced species
rm(raretaxa)
XFormula1 <- as.formula(~be10+B11_median+mean.EVI+insideHJA + Ess + ht + ht.r500 + cov4_16 + cov4_16.r500 + mTopo)
# check names
all(all.vars(XFormula1) %in% names(X.train))
str(X.train)
xy.scale <- X.train[,c("UTM_N", "UTM_E")]
str(X.train)
head(S.train)
xy.scale <- scale(S.train[,c("UTM_E", "UTM_N")])
head(xy.scale)
seq(0,0.1,0.001)
seq(0, 1, 0.1)
seq(0, 1, 0.2)
seq(0, 0.1, 0.001)
seq(0, 0.1, 0.01)
load("Hmsc_CD/oregon_ada/results_sjSDM/oregon_trial.rdata")
getwd()
load("results_sjSDM/oregon_trial.rdata")
