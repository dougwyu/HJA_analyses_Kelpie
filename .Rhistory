tjur.train = NA,
tjur.test = NA,
cor.train = NA,
cor.test = NA,
auc.lt5.train = NA,
auc.lt5.test= NA)
str(tune.results)
# Add in k, to keep all cross validation runs. Average later.
tune.results <- cbind(tune.results[rep(seq(noSteps), k),], k = rep(1:k, each = noSteps))
rownames(tune.results) <- NULL
head(tune.results)
# clean up
rm(lambda.env, alpha.env, lambda.sp, alpha.sp, hidden.ind, drop, sample.bio, acti.sp)
# Choose pa or qp reponse data and family
if(abund == "pa") {
Y <- otu.pa.csv
family <- stats::binomial('probit') } else {
if(abund ==  "qp") {
Y <- otu.qp.csv
family <- stats::binomial('probit') # check other family?
} else stop("check abund")
}
i= 1
j = 1
tr <- subset(tune.results, k == i)[j,,drop = T]
tr
for(i in 1:k){ # start fold loop
# select X data
env.train <- env.vars[fold.id != i, vars]
env.test <- env.vars[fold.id == i, vars]
# any(sapply(env.train, function(x) any(is.na(x))))
# any(sapply(env.test, function(x) any(is.na(x))))
# select spatial data
XY.train <- env.vars[fold.id != i, c("UTM_E", "UTM_N")]
XY.test <- env.vars[fold.id == i, c("UTM_E", "UTM_N")]
# select Y data
s.otu.train <- as.matrix(Y[fold.id != i,])
s.otu.test <- as.matrix(Y[fold.id == i,])
factV <- colnames(env.train)[sapply(env.train, is.factor)]
# scale X and spatial data for each fold
# .. env data - without factors
scale.env.train.all = dplyr::select(env.train, -any_of(factV)) %>% scale()
# str(scale.env.train.all)
# put factors back in
scale.env.train <- data.frame(scale.env.train.all, env.train[,factV, drop = F])
# data frame of means and sd for scaling
dd.env.scaler = data.frame(t(data.frame(env.mean = attr(scale.env.train.all, "scaled:center"), env.sd = attr(scale.env.train.all, "scaled:scale"))))
scale.env.test = as.data.frame(do.call(rbind,apply(dplyr::select(env.test, -any_of(factV)), 1, function(x){(x-dd.env.scaler['env.mean',])/dd.env.scaler['env.sd',]} ) )) %>%
tibble::add_column(env.test[,factV, drop = F])
#dim(scale.env.train)
#dim(scale.env.test)
# .. spatial data
XY.train.scale <- scale(XY.train)
dd.xy.scaler = data.frame(t(data.frame(sp.mean = attr(XY.train.scale, "scaled:center"),
sp.sd = attr(XY.train.scale, "scaled:scale"))))
XY.test.scale <- as.data.frame(do.call(rbind,
apply(XY.test, 1,function(x){(x-dd.xy.scaler['sp.mean',])/dd.xy.scaler['sp.sd',]})))
rm(dd.xy.scaler, dd.env.scaler, scale.env.train.all)
XY.train.scale <- data.frame(XY.train.scale)
rm(env.test, env.train, XY.test, XY.train)
# summary(scale.env.train)
# summary(scale.env.test)
## Do tuning per k
# j = 1 # j= 2
for(j in seq_len(noSteps)){
#lambda.bioN = sample(1:11,1)
#alpha.bioN = sample(1:11,1)
cat("\nk", i, "tune run", j)
# print(tune.results[tune.results$k == i, ][j,])
# subset this round of tuning parameters to make easier to insert in model specs
tr <- subset(tune.results, k == i)[j,,drop = T]
# do model
model.train <- sjSDM(
Y = s.otu.train,
env = DNN(data=scale.env.train, formula = ~.,
hidden=hidden[[tr$hidden.ind]],
lambda = tr$lambda.env,
alpha = tr$alpha.env,
activation = tr$acti.sp,
dropout=tr$drop,
bias=T),
biotic = bioticStruct(lambda=tr$lambda.bio,
alpha=tr$alpha.bio,
on_diag=F, inverse = FALSE),
spatial = linear(data=XY.train.scale, ~0+UTM_E*UTM_N,
lambda=tr$lambda.sp,
alpha=tr$alpha.sp),
learning_rate = tr$lr, # part of tuning grid
iter = iter,
family = family,
sampling = sampling, # 150L, 5000L
device = device
)
## SAve each model
saveRDS(model.train,
file.path(resFolder,paste0("s-jSDM_tuning_model_", varsName, "_", k, "CV_",
i, "_tr_", j, "_", abund, ".rds")))
# Do testing and save results in data frame
tune.results$loglike_sjSDM[tune.results$k == i][j] <- logLik(model.train)
tune.results$loss[tune.results$k == i][j] <-model.train$history[length(model.train$history)]
## Model evaluation - AUC, LL, r2 -- could put all this into same loop over species columns, then use colMeans, etc below.
## put togehter from different metric scripts.
for (pred in 1:2) {
# pred = 1
# 1 -> 'test'
newdd = scale.env.test ; newsp = XY.test.scale; otudd = s.otu.test
## pred = 2 # training
if (pred==2) { newdd = NULL; newsp = NULL; otudd = s.otu.train}
# Error in reticulate::py_is_null_xptr(fa) :
#   Cannot convert object to an environment: [type=double; target=ENVSXP].
# if (pred==2) { newdd = scale.env.train; newsp = XY.train.scale; otudd = s.otu.train}
# predict for all species = sites X columns
pred.dd = apply(abind::abind(lapply(1:3, function(i) {
predict(model.train, newdata=newdd, SP=newsp)}
),along = -1L), 2:3, mean)
attr(pred.dd, 'dimnames') = NULL
# convert observed to pa (if qp)
otudd.pa = (otudd>0)*1
# sum(colSums(otudd.pa)==0)
# AUC for all species - if not present, then NA
auc <- sapply(1:dim(otudd)[2], function(i) {
tryCatch({
as.numeric(pROC::roc(otudd.pa[,i], pred.dd[,i], direction = "<", quiet=T)$auc)},
error = function(err){ return(NA)}
)
})
## Extra evaluation metrics
# ll, nagel & plr for spp
rsq = data.frame(ll=rep(.1, length.out=ncol(pred.dd)),
nagel=rep(.1, length.out=ncol(pred.dd)),
plr=rep(.1, length.out=ncol(pred.dd)),
tjur = rep(NA, length.out=ncol(pred.dd)),
cor = rep(NA, length.out=ncol(pred.dd)))
# m = 59
for (m in 1:ncol(pred.dd)) {
p = pred.dd[,m]; y = otudd.pa[,m]
loglikP = sum( log( p*y + (1-p)*(1-y) ) )
loglikN = sum( log( mean(p)*y + (1-mean(p))*(1-y) ) )
rsq$nagel[m] = (1-exp(2/length(p)*(loglikN-loglikP))) / (1-exp(2/length(p)*loglikN))
rsq$ll[m] = loglikP
tppp = sum(p*y)
fppp = sum(p*(1-y))
fapp = sum((1-p)*y) ### Weird behavious if fa object is here... check in sjSDM code...
tapp = sum((1-p)*(1-y))
rsq$plr[m] = tppp/(tppp+fapp)/fppp*(fppp+tapp) # get NaN if species missing at all sites. OK>
tjur <- base::diff(tapply(p, y, mean, na.rm = T))
rsq$tjur[m] <- ifelse(length(tjur) > 0, tjur, NA)
rsq$cor[m] = suppressWarnings(cor(p, y)) # warning - with NaN when no presences in species in test set
}
# Tjur <- tryCatch(expr = mapply(function(x,y) {
#   tj <- base::diff(tapply(x, y, mean, na.rm = T)) # difference of average predicted values at 1 and 0
#   if(!length(tj) > 0) tj <- NA
#   return(tj)
# }, asplit(pred.dd,2), asplit(otudd.pa,2)), error = function(err){ return(NA)})
#
## add to data frame
# if (pred==2) {tune.results$AUC.train[tune.results$k == i][j] = mean(auc, na.rm = TRUE)}
# if (pred==1) {tune.results$AUC.test[tune.results$k == i][j] = mean(auc, na.rm = TRUE)}
#
if (pred==2) {
tune.results$AUC.train[tune.results$k == i][j] = mean(auc, na.rm = TRUE)
tune.results$ll.train[tune.results$k == i][j] = mean(rsq$ll, na.rm = T)
tune.results$nagel.train[tune.results$k == i][j] = mean(rsq$nagel, na.rm = T)
tune.results$plr.train[tune.results$k == i][j]  = mean(rsq$plr, na.rm = T)
tune.results$tjur.train[tune.results$k == i][j]  = mean(rsq$tjur, na.rm = T)
tune.results$cor.train[tune.results$k == i][j]  = mean(rsq$cor, na.rm = T)
tune.results$auc.lt5.train[tune.results$k == i][j]  = sum(auc < 0.5, na.rm = T)
}
if (pred==1) {
tune.results$AUC.test[tune.results$k == i][j] = mean(auc, na.rm = TRUE)
tune.results$ll.test[tune.results$k == i][j] = mean(rsq$ll, na.rm = T)
tune.results$nagel.test[tune.results$k == i][j] = mean(rsq$nagel, na.rm = T)
tune.results$plr.test[tune.results$k == i][j] = mean(rsq$plr, na.rm = T)
tune.results$tjur.test[tune.results$k == i][j]  = mean(rsq$tjur, na.rm = T)
tune.results$cor.test[tune.results$k == i][j]  = mean(rsq$cor, na.rm = T)
tune.results$auc.lt5.test[tune.results$k == i][j]  = sum(auc < 0.5, na.rm = T)
}
} # end of evaluation loop
rm(model.train)
} # end of model loop
}
library(sjSDM)
for(i in 1:k){ # start fold loop
# select X data
env.train <- env.vars[fold.id != i, vars]
env.test <- env.vars[fold.id == i, vars]
# any(sapply(env.train, function(x) any(is.na(x))))
# any(sapply(env.test, function(x) any(is.na(x))))
# select spatial data
XY.train <- env.vars[fold.id != i, c("UTM_E", "UTM_N")]
XY.test <- env.vars[fold.id == i, c("UTM_E", "UTM_N")]
# select Y data
s.otu.train <- as.matrix(Y[fold.id != i,])
s.otu.test <- as.matrix(Y[fold.id == i,])
factV <- colnames(env.train)[sapply(env.train, is.factor)]
# scale X and spatial data for each fold
# .. env data - without factors
scale.env.train.all = dplyr::select(env.train, -any_of(factV)) %>% scale()
# str(scale.env.train.all)
# put factors back in
scale.env.train <- data.frame(scale.env.train.all, env.train[,factV, drop = F])
# data frame of means and sd for scaling
dd.env.scaler = data.frame(t(data.frame(env.mean = attr(scale.env.train.all, "scaled:center"), env.sd = attr(scale.env.train.all, "scaled:scale"))))
scale.env.test = as.data.frame(do.call(rbind,apply(dplyr::select(env.test, -any_of(factV)), 1, function(x){(x-dd.env.scaler['env.mean',])/dd.env.scaler['env.sd',]} ) )) %>%
tibble::add_column(env.test[,factV, drop = F])
#dim(scale.env.train)
#dim(scale.env.test)
# .. spatial data
XY.train.scale <- scale(XY.train)
dd.xy.scaler = data.frame(t(data.frame(sp.mean = attr(XY.train.scale, "scaled:center"),
sp.sd = attr(XY.train.scale, "scaled:scale"))))
XY.test.scale <- as.data.frame(do.call(rbind,
apply(XY.test, 1,function(x){(x-dd.xy.scaler['sp.mean',])/dd.xy.scaler['sp.sd',]})))
rm(dd.xy.scaler, dd.env.scaler, scale.env.train.all)
XY.train.scale <- data.frame(XY.train.scale)
rm(env.test, env.train, XY.test, XY.train)
# summary(scale.env.train)
# summary(scale.env.test)
## Do tuning per k
# j = 1 # j= 2
for(j in seq_len(noSteps)){
#lambda.bioN = sample(1:11,1)
#alpha.bioN = sample(1:11,1)
cat("\nk", i, "tune run", j)
# print(tune.results[tune.results$k == i, ][j,])
# subset this round of tuning parameters to make easier to insert in model specs
tr <- subset(tune.results, k == i)[j,,drop = T]
# do model
model.train <- sjSDM(
Y = s.otu.train,
env = DNN(data=scale.env.train, formula = ~.,
hidden=hidden[[tr$hidden.ind]],
lambda = tr$lambda.env,
alpha = tr$alpha.env,
activation = tr$acti.sp,
dropout=tr$drop,
bias=T),
biotic = bioticStruct(lambda=tr$lambda.bio,
alpha=tr$alpha.bio,
on_diag=F, inverse = FALSE),
spatial = linear(data=XY.train.scale, ~0+UTM_E*UTM_N,
lambda=tr$lambda.sp,
alpha=tr$alpha.sp),
learning_rate = tr$lr, # part of tuning grid
iter = iter,
family = family,
sampling = sampling, # 150L, 5000L
device = device
)
## SAve each model
saveRDS(model.train,
file.path(resFolder,paste0("s-jSDM_tuning_model_", varsName, "_", k, "CV_",
i, "_tr_", j, "_", abund, ".rds")))
# Do testing and save results in data frame
tune.results$loglike_sjSDM[tune.results$k == i][j] <- logLik(model.train)
tune.results$loss[tune.results$k == i][j] <-model.train$history[length(model.train$history)]
## Model evaluation - AUC, LL, r2 -- could put all this into same loop over species columns, then use colMeans, etc below.
## put togehter from different metric scripts.
for (pred in 1:2) {
# pred = 1
# 1 -> 'test'
newdd = scale.env.test ; newsp = XY.test.scale; otudd = s.otu.test
## pred = 2 # training
if (pred==2) { newdd = NULL; newsp = NULL; otudd = s.otu.train}
# Error in reticulate::py_is_null_xptr(fa) :
#   Cannot convert object to an environment: [type=double; target=ENVSXP].
# if (pred==2) { newdd = scale.env.train; newsp = XY.train.scale; otudd = s.otu.train}
# predict for all species = sites X columns
pred.dd = apply(abind::abind(lapply(1:3, function(i) {
predict(model.train, newdata=newdd, SP=newsp)}
),along = -1L), 2:3, mean)
attr(pred.dd, 'dimnames') = NULL
# convert observed to pa (if qp)
otudd.pa = (otudd>0)*1
# sum(colSums(otudd.pa)==0)
# AUC for all species - if not present, then NA
auc <- sapply(1:dim(otudd)[2], function(i) {
tryCatch({
as.numeric(pROC::roc(otudd.pa[,i], pred.dd[,i], direction = "<", quiet=T)$auc)},
error = function(err){ return(NA)}
)
})
## Extra evaluation metrics
# ll, nagel & plr for spp
rsq = data.frame(ll=rep(.1, length.out=ncol(pred.dd)),
nagel=rep(.1, length.out=ncol(pred.dd)),
plr=rep(.1, length.out=ncol(pred.dd)),
tjur = rep(NA, length.out=ncol(pred.dd)),
cor = rep(NA, length.out=ncol(pred.dd)))
# m = 59
for (m in 1:ncol(pred.dd)) {
p = pred.dd[,m]; y = otudd.pa[,m]
loglikP = sum( log( p*y + (1-p)*(1-y) ) )
loglikN = sum( log( mean(p)*y + (1-mean(p))*(1-y) ) )
rsq$nagel[m] = (1-exp(2/length(p)*(loglikN-loglikP))) / (1-exp(2/length(p)*loglikN))
rsq$ll[m] = loglikP
tppp = sum(p*y)
fppp = sum(p*(1-y))
fapp = sum((1-p)*y) ### Weird behavious if fa object is here... check in sjSDM code...
tapp = sum((1-p)*(1-y))
rsq$plr[m] = tppp/(tppp+fapp)/fppp*(fppp+tapp) # get NaN if species missing at all sites. OK>
tjur <- base::diff(tapply(p, y, mean, na.rm = T))
rsq$tjur[m] <- ifelse(length(tjur) > 0, tjur, NA)
rsq$cor[m] = suppressWarnings(cor(p, y)) # warning - with NaN when no presences in species in test set
}
# Tjur <- tryCatch(expr = mapply(function(x,y) {
#   tj <- base::diff(tapply(x, y, mean, na.rm = T)) # difference of average predicted values at 1 and 0
#   if(!length(tj) > 0) tj <- NA
#   return(tj)
# }, asplit(pred.dd,2), asplit(otudd.pa,2)), error = function(err){ return(NA)})
#
## add to data frame
# if (pred==2) {tune.results$AUC.train[tune.results$k == i][j] = mean(auc, na.rm = TRUE)}
# if (pred==1) {tune.results$AUC.test[tune.results$k == i][j] = mean(auc, na.rm = TRUE)}
#
if (pred==2) {
tune.results$AUC.train[tune.results$k == i][j] = mean(auc, na.rm = TRUE)
tune.results$ll.train[tune.results$k == i][j] = mean(rsq$ll, na.rm = T)
tune.results$nagel.train[tune.results$k == i][j] = mean(rsq$nagel, na.rm = T)
tune.results$plr.train[tune.results$k == i][j]  = mean(rsq$plr, na.rm = T)
tune.results$tjur.train[tune.results$k == i][j]  = mean(rsq$tjur, na.rm = T)
tune.results$cor.train[tune.results$k == i][j]  = mean(rsq$cor, na.rm = T)
tune.results$auc.lt5.train[tune.results$k == i][j]  = sum(auc < 0.5, na.rm = T)
}
if (pred==1) {
tune.results$AUC.test[tune.results$k == i][j] = mean(auc, na.rm = TRUE)
tune.results$ll.test[tune.results$k == i][j] = mean(rsq$ll, na.rm = T)
tune.results$nagel.test[tune.results$k == i][j] = mean(rsq$nagel, na.rm = T)
tune.results$plr.test[tune.results$k == i][j] = mean(rsq$plr, na.rm = T)
tune.results$tjur.test[tune.results$k == i][j]  = mean(rsq$tjur, na.rm = T)
tune.results$cor.test[tune.results$k == i][j]  = mean(rsq$cor, na.rm = T)
tune.results$auc.lt5.test[tune.results$k == i][j]  = sum(auc < 0.5, na.rm = T)
}
} # end of evaluation loop
rm(model.train)
} # end of model loop
}
write.table(tune.results,
file = file.path(resFolder,paste0("manual_tuning_sjsdm_", varsName, "_", k, "CV_M1S1_",
abund,
"_min",
minocc,
"_nSteps",
noSteps,
".csv")), row.names=F, sep=',')
head(tune.results)
tune.mean <- tune.results %>%
group_by(across(c(-loglike_sjSDM, -loss, -k, -contains(c("train", "test"))))) %>%
#summarise(across(contains(c("train", "test"))), list(mean))
summarise(across(contains(c("train", "test")), list(mean = mean)))
data.frame(tune.mean)
tune.mean <- tune.mean[sort(tune.mean$AUC.test_mean, increasing = FALSE), ]
tune.mean <- tune.mean[sort(tune.mean$AUC.test_mean, decreasing = TRUE), ]
tune.mean <- tune.results %>%
group_by(across(c(-loglike_sjSDM, -loss, -k, -contains(c("train", "test"))))) %>%
#summarise(across(contains(c("train", "test"))), list(mean))
summarise(across(contains(c("train", "test")), list(mean = mean)))%>%
arrange(desc(AUC.test_mean))
data.frame(tune.mean)
head(data.frame(tune.mean))
write.table(tune.mean,
file = file.path(resFolder,paste0("manual_tuning_sjsdm_", varsName, "_", k, "CV_M1S1_meanEVAL_",
abund,
"_min",
minocc,
"_nSteps",
noSteps,
".csv")), row.names=F, sep=',')
t1 <- "26/03/2021 12:51:13"
t2 <- "26/03/2021 13:05:00"
n <- 50*5 # number of models, nSteps * k
ms <- difftime(strptime(t1, format = "%d/%m/%Y %H:%M:%S", tz = "GMT"),
strptime(t2, format = "%d/%m/%Y %H:%M:%S", tz = "GMT"),
units = "mins")
ms
n/ms
n/as.numeric(ms)
ms <- difftime(strptime(t2, format = "%d/%m/%Y %H:%M:%S", tz = "GMT"),
strptime(t1, format = "%d/%m/%Y %H:%M:%S", tz = "GMT"),
units = "mins")
n/as.numeric(ms)
t1 <- "26/03/2021 12:51:13"
t2 <- "26/03/2021 13:05:00"
n <- 50*5 # number of models, nSteps * k
ms <- difftime(strptime(t2, format = "%d/%m/%Y %H:%M:%S", tz = "GMT"),
strptime(t1, format = "%d/%m/%Y %H:%M:%S", tz = "GMT"),
units = "mins")
ms
n/as.numeric(ms)
n
as.numeric(ms)/n
t1 <- "26/03/2021 12:57:32"
t2 <- "26/03/2021 13:36:04"
#n <- 50*5 # number of models, nSteps * k
n <- 102
ms <- difftime(strptime(t2, format = "%d/%m/%Y %H:%M:%S", tz = "GMT"),
strptime(t1, format = "%d/%m/%Y %H:%M:%S", tz = "GMT"),
units = "mins")
ms
(tpm <- as.numeric(ms)/n)
k <- 5
nSteps <- 1000
(k*nSteps * tpm)/60
t1 <- "26/03/2021 13:00:31"
t2 <- "26/03/2021 13:40:00"
#n <- 50*5 # number of models, nSteps * k
n <- 103
ms <- difftime(strptime(t2, format = "%d/%m/%Y %H:%M:%S", tz = "GMT"),
strptime(t1, format = "%d/%m/%Y %H:%M:%S", tz = "GMT"),
units = "mins")
ms
(tpm <- as.numeric(ms)/n)
k <- 5
nSteps <- 1000
# Total run time
(k*nSteps * tpm)/60
getwd()
wd <- here::here()
setwd(wd)
dir()
resFolder <- "r20210319a"
tune.df <- read.csv(file.path("Hmsc_CD/oregon_ada/code_sjSDM", resFolder,
"manual_tuning_sjsdm_vars3_5CV_M1S1_meanEVAL_pa_min6_nSteps2000.csv")
)
tune.df <- read.csv(file.path("Hmsc_CD/oregon_ada/code_sjSDM", resFolder, "results",
"manual_tuning_sjsdm_vars3_5CV_M1S1_meanEVAL_pa_min6_nSteps2000.csv"))
head(tune.df)
paste(colnames(tune.df), collapse = '", "')
cat(paste(colnames(tune.df), collapse = '", "'))
library(vegan)
nmds1 <- metaMDS(tune.df[,hyper], k = 2, try = 50, trymax = 50)
hyper <- c("lambda.env", "alpha.env", "lambda.sp", "alpha.sp", "hidden.ind", "drop", "lambda.bio", "alpha.bio")
nmds1 <- metaMDS(tune.df[,hyper], k = 2, try = 50, trymax = 50)
nmds1
eval <- c("AUC.test_mean", "nagel.test_mean", "plr.test_mean", "tjur.test_mean", "auc.lt5.test_mean")
envfit1 <- envfit(nmds1, tune.df[, eval])
dir()
dir("Hmsc_CD")
save(nmds1, envfit1, file = "Hmsc_CD/working_cd/tuneSpace.rdata")
plot(nmds1)
plot(envfit1)
reds <- colorRampPalette(c("lightred", "darkred"))
reds <- colorRampPalette(c("pink", "darkred"))
plot(nmds1, col = reds(50)[order(tune.df$AUC.test_mean)])
plot(nmds1)
plot(nmds1, display = "sites")
plot(nmds1, display = "species")
points(nmds1, what = "sites", col = reds(50)[order(tune.df$AUC.test_mean)])
points(nmds1, type = "sites", col = reds(50)[order(tune.df$AUC.test_mean)])
plot(nmds1)
points(nmds1, "sites", col = reds(50)[order(tune.df$AUC.test_mean)])
str(nmds1)
points(nmds1$points, col = reds(50)[order(tune.df$AUC.test_mean)], pch = 16)
plots(nmds1$points, col = reds(50)[order(tune.df$AUC.test_mean)], pch = 16)
plot(nmds1$points, col = reds(50)[order(tune.df$AUC.test_mean)], pch = 16)
plot(nmds1$points, col = reds(2000)[order(tune.df$AUC.test_mean)], pch = 16)
plot(nmds1$points, col = reds(2000)[order(tune.df$AUC.test_mean)], pch = 16, asp = 1)
plot(tune.df[,hyper[1:2]])
plot(tune.df[,hyper[1:2]], col = reds(2000)[order(tune.df$AUC.test_mean)], pch = 16, asp = 1)
plot(tune.df[,hyper[c(1,3)]], col = reds(2000)[order(tune.df$AUC.test_mean)], pch = 16, asp = 1)
plot(tune.df[,hyper[c(1,2)]], col = reds(2000)[order(tune.df$AUC.test_mean)], pch = 16, asp = 1)
plot(tune.df[,hyper[c(3,4)]], col = reds(2000)[order(tune.df$AUC.test_mean)], pch = 16, asp = 1)
plot(nmds1$points, col = reds(2000)[order(tune.df$AUC.test_mean)], pch = 16, asp = 1)
plot(envfit1)
rda1 <- rda(tune.df[,hyper])
plot(rda)
plot(rda1)
plot(scores(rda1)[,1:2])
scores(rda1)
plot(scores(rda1)$species)
plot(scores(rda1)$species[,1:2])
scores(rda1)$species
plot(scores(rda1)$sites[,1:2])
plot(scores(rda1)$sites[,1:2], col = reds(2000)[order(tune.df$AUC.test_mean)], pch = 16)
summary(tune.df)
hyper <- c("lambda.env", "alpha.env", "lambda.sp", "alpha.sp", "drop", "lambda.bio", "alpha.bio") # hidden.ind
eval <- c("AUC.test_mean", "nagel.test_mean", "plr.test_mean", "tjur.test_mean", "auc.lt5.test_mean")
nmds1 <- metaMDS(tune.df[,hyper], k = 2, try = 50, trymax = 50)
plot(nmds1$points, col = reds(2000)[order(tune.df$AUC.test_mean)], pch = 16, asp = 1)
###CHECK THESE FROM OTHER SCRIPT
lambda.env = seq(0,1, length.out=6)	# .1
alpha.env = seq(0,1, length.out=6)		# .9
lambda.sp = seq(0,1, length.out=5)	# .1 ## Changed to 5
alpha.sp =  seq(0,1, length.out=5)	# .5 ## Changed to 5
hidden <- list(c(50L,50L,10L), c(25L,25L,10L))
hidden.ind = seq_along(hidden)
acti.sp = 'relu'
drop = seq(0.1,0.4, length.out=4) # .3
sample.bio = seq(0,1,length.out=11)
## Make grid of priority tune parameters, choose, from these in sampling, then add lower priority parameters
tune.grid <- expand.grid(lambda.env = lambda.env, alpha.env= alpha.env, lambda.sp = lambda.sp,
alpha.sp = alpha.sp, hidden.ind = hidden.ind,
drop= drop, acti.sp = acti.sp, stringsAsFactors = FALSE)
head(tune.grid)
lambda.env = seq(0,1, length.out=6)	# .1
alpha.env = seq(0,1, length.out=6)		# .9
lambda.sp = seq(0,1, length.out=5)	# .1 ## Changed to 5
alpha.sp =  seq(0,1, length.out=5)	# .5 ## Changed to 5
hidden <- list(c(50L,50L,10L), c(25L,25L,10L))
hidden.ind = seq_along(hidden)
acti.sp = 'relu'
drop = seq(0.1,0.4, length.out=4) # .3
sample.bio = seq(0,1,length.out=11)
lr = c(0.001, 0.002, 0.003)
## Make grid of priority tune parameters, choose, from these in sampling, then add lower priority parameters
tune.grid <- expand.grid(lambda.env = lambda.env, alpha.env= alpha.env, lambda.sp = lambda.sp,
alpha.sp = alpha.sp, lr= lr, hidden.ind = hidden.ind,
drop= drop, acti.sp = acti.sp, stringsAsFactors = FALSE)
head(tune.grid)
6*6*5*5*3*4*3
6*6*5*5*3*3*4
6*6*5*5*3*2*4
