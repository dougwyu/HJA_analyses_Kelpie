raretaxa <- which(colSums(otu.pa.csv > 0) < 5)
length(raretaxa)
otu.pa.minocc <- as.matrix(otu.pa.csv[, -raretaxa]) # reduced species
rm(raretaxa)
# scale all togher for now... just for test
env.vars.scale <- env.vars %>%
mutate(across(where(is.numeric), scale))
# XFormula1 <- as.formula(~be10+B11_median+mean.EVI+insideHJA + Ess + ht + ht.r500 + cov4_16 + cov4_16.r500 + mTopo)
# check names
# all(all.vars(XFormula1) %in% names(env.vars.scale))
# spatial data here:
head(Sp.data)
# scale spatial coords
Sp.data.scale <- scale(Sp.data[, c("UTM_E", "UTM_N")])
head(Sp.data.scale)
is.matrix(Sp.data.scale)
# this is what goes into the model
# mm <- model.matrix(XFormula1, data = env.vars.scale)
# head(mm)
head(env.vars.scale)
otu.pa.minocc
View(otu.pa.minocc)
raretaxa <- which(colSums(otu.pa.csv > 0) < 5)
length(raretaxa)
raretaxa <- which(colSums(otu.pa.csv > 0) < 10)
length(raretaxa)
otu.pa.minocc <- as.matrix(otu.pa.csv[, -raretaxa]) # reduced species
rm(raretaxa)
source("code_sjSDM/S1_read_data.r")
# gets env.vars, out.pa.csv, otu.qp.csv, S.train
rm(P, otu.qp.csv)
# Data reduction - reduce species
raretaxa <- which(colSums(otu.pa.csv > 0) < 10)
length(raretaxa)
otu.pa.minocc <- as.matrix(otu.pa.csv[, -raretaxa]) # reduced species
rm(raretaxa)
# scale all togher for now... just for test
env.vars.scale <- env.vars %>%
mutate(across(where(is.numeric), scale))
head(env.vars.scale)
# XFormula1 <- as.formula(~be10+B11_median+mean.EVI+insideHJA + Ess + ht + ht.r500 + cov4_16 + cov4_16.r500 + mTopo)
# check names
# all(all.vars(XFormula1) %in% names(env.vars.scale))
# spatial data here:
head(Sp.data)
# scale spatial coords
Sp.data.scale <- scale(Sp.data[, c("UTM_E", "UTM_N")])
head(Sp.data.scale)
is.matrix(Sp.data.scale)
# this is what goes into the model
# mm <- model.matrix(XFormula1, data = env.vars.scale)
model <- sjSDM(Y = otu.pa.minocc,
env = linear(data = env.vars.scale,
formula = ~be10+B11_median+mean.EVI+insideHJA + Ess + ht + ht.r500 +
cov4_16 + cov4_16.r500 + mTopo), # linear model on env covariates
spatial = linear(data = Sp.data.scale, formula = ~0+UTM_E:UTM_N), # interactions of coordinates
se = TRUE, family=binomial("probit"), sampling = 1000L, iter = 100L,
device = "cpu")
head(env.vars.scale)
setwd("J:/UEA/gitHRepos/HJA_analyses_Kelpie/Hmsc_CD/oregon_ada")
load("Hmsc_CD/oregon_ada/results_sjSDM/oregon_trial_tune2.rdata")
dir("Hmsc_CD/oregon_ada/results_sjSDM")
getwd()
wd <- here::here()
setwd(wd)
getwd()
rm(wd)
load("Hmsc_CD/oregon_ada/results_sjSDM/oregon_trial_tune2.rdata")
best
plot(tune_results, perf = "logLik")
seq(0, 1, 0.2)
seq(0, 0.1, 0.01)
setwd("J:/UEA/gitHRepos/HJA_analyses_Kelpie/Hmsc_CD/oregon_ada")
source("code_sjSDM/S1_read_data.r")
raretaxa <- which(colSums(otu.pa.csv > 0) < 10)
length(raretaxa)
otu.pa.minocc <- as.matrix(otu.pa.csv[, -raretaxa]) # reduced species
rm(raretaxa)
env.vars.scale <- env.vars %>%
mutate(across(where(is.numeric), scale))
head(env.vars.scale)
env.vars.old <- env.vars.scale[, c("insideHJA", "elevation_f", "canopyHeight_f", "minT_annual", "precipitation_mm", "distToRoad_m", "distToStream_m", "YrsSinceDist", "B1_20180717", "B2_20180717", "B3_20180717", "B4_20180717", "B5_20180717", "B6_20180717", "B7_20180717", "B10_20180717", "B11_20180717", "NDVI_20180717", "EVI_20180717", "B_20180717", "G_20180717", "W_20180717", "l_Cover_2m_max", "l_Cover_2m_4m", "l_Cover_4m_16m", "l_p25", "l_p95", "l_rumple")]
env.vars.new <- env.vars.scale[, c("be10", "tri", "slope", "Nss", "Ess", "ht", "ht.r250", "ht.r500", "ht.r1k", "cov2_4", "cov2_4.r250", "cov2_4.r500", "cov2_4.r1k", "cov4_16", "cov4_16.r250", "cov4_16.r500", "cov4_16.r1k", "be500", "mTopo", "cut.r1k.pt", "insideHJA", "minT_annual", "maxT_annual", "precipitation_mm", "lg_DistStream", "lg_DistRoad", "lg_YrsDisturb", "B1_20180717", "B2_20180717", "B3_20180717", "B4_20180717", "B5_20180717", "B6_20180717", "B7_20180717", "B10_20180717", "B11_20180717", "NDVI_20180717", "EVI_20180717", "B_20180717", "G_20180717", "W_20180717", "l_p25", "l_rumple")]
3^6
env.vars.old <- env.vars.scale[, c("insideHJA", "elevation_f", "canopyHeight_f", "minT_annual", "precipitation_mm", "distToRoad_m", "distToStream_m", "YrsSinceDist", "B1_20180717", "B2_20180717", "B3_20180717", "B4_20180717", "B5_20180717", "B6_20180717", "B7_20180717", "B10_20180717", "B11_20180717", "NDVI_20180717", "EVI_20180717", "B_20180717", "G_20180717", "W_20180717", "l_Cover_2m_max", "l_Cover_2m_4m", "l_Cover_4m_16m", "l_p25", "l_p95", "l_rumple")]
env.vars.old <- env.vars.scale[, c("insideHJA", "elevation_m", "canopyHeight_m", "minT_annual", "precipitation_mm", "distToRoad_m", "distToStream_m", "YrsSinceDist", "B1_20180717", "B2_20180717", "B3_20180717", "B4_20180717", "B5_20180717", "B6_20180717", "B7_20180717", "B10_20180717", "B11_20180717", "NDVI_20180717", "EVI_20180717", "B_20180717", "G_20180717", "W_20180717", "l_Cover_2m_max", "l_Cover_2m_4m", "l_Cover_4m_16m", "l_p25", "l_p95", "l_rumple")]
env.vars.old <- env.vars.scale[, c("insideHJA", "elevation_m", "canopyHeight_m", "minT_annual", "precipitation_mm", "lg_DistRoad", "lg_DistStream", "lg_YrsDisturb", "B1_20180717", "B2_20180717", "B3_20180717", "B4_20180717", "B5_20180717", "B6_20180717", "B7_20180717", "B10_20180717", "B11_20180717", "NDVI_20180717", "EVI_20180717", "B_20180717", "G_20180717", "W_20180717", "l_Cover_2m_max", "l_Cover_2m_4m", "l_Cover_4m_16m", "l_p25", "l_p95", "l_rumple")]
env.vars.old <- env.vars.scale[, c("insideHJA", "elevation_m", "canopyHeight_m", "minT_annual", "precipitation_mm", "lg_DistRoad", "lg_DistStream", "lg_YrsDisturb", "B1_20180717", "B2_20180717", "B3_20180717", "B4_20180717", "B5_20180717", "B6_20180717", "B7_20180717", "B10_20180717", "B11_20180717", "NDVI_20180717", "EVI_20180717", "B_20180717", "G_20180717", "W_20180717", "lg_Cover_2m_max", "lg_Cover_2m_4m", "lg_Cover_4m_16m", "l_p25", "l_p95", "l_rumple")]
env.vars.old <- env.vars.scale[, c("insideHJA", "elevation_m", "canopyHeight_m", "minT_annual", "precipitation_mm", "lg_DistRoad", "lg_DistStream", "lg_YrsDisturb", "B1_20180717", "B2_20180717", "B3_20180717", "B4_20180717", "B5_20180717", "B6_20180717", "B7_20180717", "B10_20180717", "B11_20180717", "NDVI_20180717", "EVI_20180717", "B_20180717", "G_20180717", "W_20180717", "lg_cover_2m_max", "lg_cover_2m_4m", "lg_cover_4m_16m", "l_p25", "l_p95", "l_rumple")]
env.vars.old <- env.vars.scale[, c("insideHJA", "elevation_m", "canopyHeight_m", "minT_annual", "precipitation_mm", "lg_DistRoad", "lg_DistStream", "lg_YrsDisturb", "B1_20180717", "B2_20180717", "B3_20180717", "B4_20180717", "B5_20180717", "B6_20180717", "B7_20180717", "B10_20180717", "B11_20180717", "NDVI_20180717", "EVI_20180717", "B_20180717", "G_20180717", "W_20180717", "lg_cover2m_max", "lg_cover2m_4m", "lg_cover4m_16m", "l_p25", "l_p95", "l_rumple")]
source("code_sjSDM/S1_read_data.r")
rm(P, otu.qp.csv)
# Data reduction - reduce species
raretaxa <- which(colSums(otu.pa.csv > 0) < 10)
length(raretaxa)
otu.pa.minocc <- as.matrix(otu.pa.csv[, -raretaxa]) # reduced species
rm(raretaxa)
# scale all togher for now... just for test
env.vars.scale <- env.vars %>%
mutate(across(where(is.numeric), scale))
head(env.vars.scale)
env.vars.old <- env.vars.scale[, c("insideHJA", "elevation_m", "canopyHeight_m", "minT_annual", "precipitation_mm", "lg_DistRoad", "lg_DistStream", "lg_YrsDisturb", "B1_20180717", "B2_20180717", "B3_20180717", "B4_20180717", "B5_20180717", "B6_20180717", "B7_20180717", "B10_20180717", "B11_20180717", "NDVI_20180717", "EVI_20180717", "B_20180717", "G_20180717", "W_20180717", "lg_cover2m_max", "lg_cover2m_4m", "lg_cover4m_16m", "l_p25", "l_p95", "l_rumple")]
# new vars
env.vars.new <- env.vars.scale[, c("be10", "tri", "slope", "Nss", "Ess", "ht", "ht.r250", "ht.r500", "ht.r1k", "cov2_4", "cov2_4.r250", "cov2_4.r500", "cov2_4.r1k", "cov4_16", "cov4_16.r250", "cov4_16.r500", "cov4_16.r1k", "be500", "mTopo", "cut.r1k.pt", "insideHJA", "minT_annual", "maxT_annual", "precipitation_mm", "lg_DistStream", "lg_DistRoad", "lg_YrsDisturb", "B1_20180717", "B2_20180717", "B3_20180717", "B4_20180717", "B5_20180717", "B6_20180717", "B7_20180717", "B10_20180717", "B11_20180717", "NDVI_20180717", "EVI_20180717", "B_20180717", "G_20180717", "W_20180717", "l_p25", "l_rumple")]
# XFormula1 <- as.formula(~be10+B11_median+mean.EVI+insideHJA + Ess + ht + ht.r500 + cov4_16 + cov4_16.r500 + mTopo)
# check names
wd <- here::here()
setwd(wd)
getwd()
rm(wd)
load("Hmsc_CD/oregon_ada/results_sjSDM/oregon_trial_tune_cv2.rdata")
str(tune_results_new_vars, max.level = 1)
head(tune_results_new_vars$short_summary) # 60 steps is 60 iterations in full summary...  so 60 random choices of tuning grid.
str(tune_results_new_vars, max.level = 1)
str(tune_results_new_vars$tune_results[[1]], max.level = 1) # cross validation results
str(tune_results_new_vars$tune_results[[1]][[1]], max.level = 1) # cross validation results
load("Hmsc_CD/local/sjSDM_local/trial29_res.rdata")
plot(an)
plot(imp)
plot(an)
print(an)
coef(model)
summary(model)
mod.summ <- summary(model)
str(mod.summ, max.level = 1)
mod.summ$coefs
mod.summ$coefmat[1:10, 1:10]
str(mod.summ, max.level = 1)
mod.summ$coefmat[1:10, 1:4]
mod.summ$P[1:10, 1:10]
rownames(mod.summ)[mod.summ$coefmat[, 4] < 0.05]
str(mod.summ, max.level = 1)
29*11
rownames(mod.summ$coefmat)[mod.summ$coefmat[, 4] < 0.05]
sum(mod.summ$coefmat[, 4] < 0.05)
sig.vars <- rownames(mod.summ$coefmat)[mod.summ$coefmat[, 4] < 0.05]
var.df <- data.frame(rowN = sig.vars) %>%
tidyr::separate(col = rowN, into = c("species", "predictor"),
remove = FALSE, sep = " ")
var.df
var.df <- data.frame(rowN = sig.vars) %>%
tidyr::separate(col = rowN, into = c("species", "predictor"),
remove = FALSE, sep = " ") %>%
filter(predictor != "(Intercept)")
var.df
barchart(var.df$predictor)
barplot(table(var.df$predictor))
barplot(sort(table(var.df$predictor)))
load("Hmsc_CD/oregon_ada/results_sjSDM/oregon_trial_cf_vars.rdata")
results_new_vars
results_old_vars
mod.summ <- summary(results_old_vars)
load("Hmsc_CD/oregon_ada/results_sjSDM/oregon_trial_cf_vars.rdata")
var.sig <- function(summ, p){
print(sum(mod.summ$coefmat[, 4] < p))
sig.vars <- rownames(mod.summ$coefmat)[mod.summ$coefmat[, 4] < 0.05]
var.df <- data.frame(rowN = sig.vars) %>%
tidyr::separate(col = rowN, into = c("species", "predictor"),
remove = FALSE, sep = " ") %>%
filter(predictor != "(Intercept)")
return(var.df)
barplot(sort(table(var.df$predictor)))
}
old.df <- var.sig(summ.new)
var.sig <- function(summ, p = 0.05){
print(sum(mod.summ$coefmat[, 4] < p))
sig.vars <- rownames(mod.summ$coefmat)[mod.summ$coefmat[, 4] < 0.05]
var.df <- data.frame(rowN = sig.vars) %>%
tidyr::separate(col = rowN, into = c("species", "predictor"),
remove = FALSE, sep = " ") %>%
filter(predictor != "(Intercept)")
return(var.df)
barplot(sort(table(var.df$predictor)))
}
old.df <- var.sig(summ.new)
mod.summ <- summ.new
print(sum(mod.summ$coefmat[, 4] < p))
p = 0.05
print(sum(mod.summ$coefmat[, 4] < p))
var.sig <- function(summ, p = 0.05){
print(sum(summ$coefmat[, 4] < p))
sig.vars <- rownames(summ$coefmat)[summ$coefmat[, 4] < 0.05]
var.df <- data.frame(rowN = sig.vars) %>%
tidyr::separate(col = rowN, into = c("species", "predictor"),
remove = FALSE, sep = " ") %>%
filter(predictor != "(Intercept)")
return(var.df)
barplot(sort(table(var.df$predictor)))
}
old.df <- var.sig(summ.new)
nSig <- sum(summ$coefmat[, 4] < p)
var.sig <- function(summ, p = 0.05){
nSig <- sum(summ$coefmat[, 4] < p)
print(nSig)
if(nSig >0) {
sig.vars <- rownames(summ$coefmat)[summ$coefmat[, 4] < 0.05]
var.df <- data.frame(rowN = sig.vars) %>%
tidyr::separate(col = rowN, into = c("species", "predictor"),
remove = FALSE, sep = " ") %>%
filter(predictor != "(Intercept)")
return(var.df)
barplot(sort(table(var.df$predictor)))
}
old.df <- var.sig(summ.old)
var.sig(summ.new)
str(summ.new, max.level = 1)
str(summ.new$coefs, max.level = 1)
str(summ.new$coefs$env, max.level = 1)
summ.new$coefs$env[[1]][1:5, 1:5]
summ.new$coefs$env[[8]][1:5, 1:5]
summ.new$coefs$env[[7]][1:5, 1:5]
load("Hmsc_CD/oregon_ada/results_sjSDM/oregon_trial_cf_vars.rdata")
str(summ.new, max.level = 1)
str(summ.new$coefs, max.level = 1)
str(summ.old, max.level = 1)
summ.old$coefs[1:5, 1:0]
summ.old$coefs[1:5, 1:10]
str(summ.old, max.level = 1)
summ.old$coefs[1:29, 1:10]
str(summ.old, max.level = 1)
length(env.vars.new)
load("Hmsc_CD/oregon_ada/results_sjSDM/oregon_trial_cf_vars.rdata")
str(summ.old, max.level = 1)
load("Hmsc_CD/local/sjSDM_local/trial29_res.rdata")
mod.summ <- summary(model)
str(mod.summ, max.level = 1)
var.sig <- function(summ, p = 0.05, ...){
nSig <- sum(summ$coefmat[, 4] < p)
print(nSig)
if(nSig >0) {
sig.vars <- rownames(summ$coefmat)[summ$coefmat[, 4] < 0.05]
var.df <- data.frame(rowN = sig.vars) %>%
tidyr::separate(col = rowN, into = c("species", "predictor"),
remove = FALSE, sep = " ") %>%
filter(predictor != "(Intercept)")
return(var.df)
barplot(sort(table(var.df$predictor)), ...)
}
load("Hmsc_CD/oregon_ada/results_sjSDM/oregon_trial_cf_vars.rdata")
str(summ.old, max.level = 1)
old.df <-var.sig(summ.old)
var.sig <- function(summ, p = 0.05, ...){
nSig <- sum(summ$coefmat[, 4] < p)
print(nSig)
if(nSig >0) {
sig.vars <- rownames(summ$coefmat)[summ$coefmat[, 4] < 0.05]
var.df <- data.frame(rowN = sig.vars) %>%
tidyr::separate(col = rowN, into = c("species", "predictor"),
remove = FALSE, sep = " ") %>%
filter(predictor != "(Intercept)")
return(var.df)
barplot(sort(table(var.df$predictor)), ...)
}
old.df <-var.sig(summ.old)
new.df <- var.sig(summ.new)
summ <- summ.new
sum(summ$coefmat[, 4] < p)
p = 0.05
sum(summ$coefmat[, 4] < p)
nSig <- sum(summ$coefmat[, 4] < p, na.rm = T)
var.sig <- function(summ, p = 0.05, ...){
nSig <- sum(summ$coefmat[, 4] < p, na.rm = T)
print(nSig)
if(nSig >0) {
sig.vars <- rownames(summ$coefmat)[summ$coefmat[, 4] < 0.05]
var.df <- data.frame(rowN = sig.vars) %>%
tidyr::separate(col = rowN, into = c("species", "predictor"),
remove = FALSE, sep = " ") %>%
filter(predictor != "(Intercept)")
return(var.df)
barplot(sort(table(var.df$predictor)), ...)
}
old.df <-var.sig(summ.old)
new.df <- var.sig(summ.new)
png("Hmsc_CD/local/plots/cf_vars.png")
par(mfrow = c(1,2))
var.sig(summ.old, main = "Old")
var.sig(summ.new, main = "new")
dev.off()
var.df <- data.frame(rowN = sig.vars) %>%
tidyr::separate(col = rowN, into = c("species", "predictor"),
remove = FALSE, sep = " ") %>%
filter(predictor != "(Intercept)")
sig.vars <- rownames(summ$coefmat)[summ$coefmat[, 4] < 0.05]
var.df <- data.frame(rowN = sig.vars) %>%
tidyr::separate(col = rowN, into = c("species", "predictor"),
remove = FALSE, sep = " ") %>%
filter(predictor != "(Intercept)")
barplot(sort(table(var.df$predictor)), ...)
var.df
barplot(sort(table(var.df$predictor)))
summ <- summ.old
nSig <- sum(summ$coefmat[, 4] < p, na.rm = T)
sig.vars <- rownames(summ$coefmat)[summ$coefmat[, 4] < 0.05]
var.df <- data.frame(rowN = sig.vars) %>%
tidyr::separate(col = rowN, into = c("species", "predictor"),
remove = FALSE, sep = " ") %>%
filter(predictor != "(Intercept)")
barplot(sort(table(var.df$predictor)))
var.df
Metrics::auc
abund = 'qp'		# 'qp','pa'  # is overwritten by data file loading.
minocc = 5
trap <- "M1"; period = "S1"
date.model.run = 20210125   # !!! change accordingly
### r load data###
# otu.train <- read.csv(paste0("data/otu.train.", abund, ".csv"), header = F)
paste0("data/yuanghen_mod_data_", abund, ".rdata")
paste0("tuning_YL_", abund)
library(glue)
library(pROC)
abund = 'qp'		# 'qp','pa'  # is overwritten by data file loading.
minocc = 5
trap <- "M1"; period = "S1"
date.model.run = 20210125   # !!! change accordingly
setwd("J:/UEA/gitHRepos/HJA_analyses_Kelpie/Hmsc_CD/oregon_ada")
abund = 'qp'		# 'qp','pa'  # is overwritten by data file loading.
minocc = 5
trap <- "M1"; period = "S1"
date.model.run = 20210125   # !!! change accordingly
### r load data###
# otu.train <- read.csv(paste0("data/otu.train.", abund, ".csv"), header = F)
# scale.env.train <- read.table("data/scale.e
load(paste0("data/yuanghen_mod_data_", abund, ".rdata"))
s.otu.train = as.matrix(s.otu.train)
attr(s.otu.train, 'dimnames') = NULL
str(s.otu.train)
names(scale.env.train)
# set variables
formula.env = 'envDNN'
lambda.env = seq(0,.3, length.out=4)	# .1
alpha.env = seq(.7,1, length.out=4)		# .9
lambda.sp = seq(0,1, length.out=7)	# .1
alpha.sp =  seq(0,1, length.out=7)	# .5
hidden = list(c(50L,50L,10L), c(25L,25L,10L))
acti.sp = 'relu'
drop = seq(.1,.5, length.out=3) # .3
sample.bio = seq(0,1,length.out=11)
# no models
4*7*7*2*3  # each lambda
# data storage
# 4*7*7*2*3 * 642
# time
# 4*7*7*2*3*2 * .5 # 162 models - 1 hour
tuning.dd = data.frame(lambda.env = numeric(),
alpha.env = numeric(),
lambda.sp = numeric(),
alpha.sp = numeric(),
lambda.bio = numeric(),
alpha.bio = numeric(),
drop = numeric(),
hidden = character(),
loglike = numeric(),
loss= numeric(),
AUC.explain=numeric(),
AUC.test=numeric())
# hiddenN <- dropN <- alpha.spN <- lambda.spN <- alpha.envN <- 1
lambda.envN = 1		# 1,2,3,4 four jobs in AD
# testing
file.path("results_sjSDM", paste0("tuning_YL_", abund),
glue::glue('s-jSDM_tuning_model_{period}_{trap}_{abund}_min{minocc}_{formula.env}_lambdaE{lambda.envN}_{alpha.envN}_{lambda.spN}_{alpha.spN}_hidden{hiddenN}_{dropN}.RDS')
)
hiddenN <- dropN <- alpha.spN <- lambda.spN <- alpha.envN <- lambda.envN <- 1
file.path("results_sjSDM", paste0("tuning_YL_", abund),
glue::glue('s-jSDM_tuning_model_{period}_{trap}_{abund}_min{minocc}_{formula.env}_lambdaE{lambda.envN}_{alpha.envN}_{lambda.spN}_{alpha.spN}_hidden{hiddenN}_{dropN}.RDS')
)
file.path("results_sjSDM",paste0("tuning_YL_", abund),
glue::glue('manual_tuning_sjsdm_{period}_{trap}_{abund}_min{minocc}_{formula.env}_{date.model.run}_lambdaE{lambda.envN}.csv')
file.path("results_sjSDM",paste0("tuning_YL_", abund),
glue::glue('manual_tuning_sjsdm_{period}_{trap}_{abund}_min{minocc}_{formula.env}_{date.model.run}_lambdaE{lambda.envN}.csv'))
file.path("results_sjSDM", paste0("tuning_YL_", abund, "_newVars"),
glue::glue('s-jSDM_tuning_model_{period}_{trap}_{abund}_min{minocc}_{formula.env}_lambdaE{lambda.envN}_{alpha.envN}_{lambda.spN}_{alpha.spN}_hidden{hiddenN}_{dropN}.RDS')
)
file.path("results_sjSDM", paste0("tuning_YL_", abund, "_newVars"),
glue::glue('s-jSDM_tuning_model_newVars{period}_{trap}_{abund}_min{minocc}_{formula.env}_lambdaE{lambda.envN}_{alpha.envN}_{lambda.spN}_{alpha.spN}_hidden{hiddenN}_{dropN}.RDS')
)
file.path("results_sjSDM", paste0("tuning_YL_", abund, "_newVars"),
glue::glue('s-jSDM_tuning_model_newVars_{period}_{trap}_{abund}_min{minocc}_{formula.env}_lambdaE{lambda.envN}_{alpha.envN}_{lambda.spN}_{alpha.spN}_hidden{hiddenN}_{dropN}.RDS')
)
file.path("results_sjSDM",paste0("tuning_YL_", abund, "_newVars"),
glue::glue('manual_tuning_sjsdm_newVars_{period}_{trap}_{abund}_min{minocc}_{formula.env}_{date.model.run}_lambdaE{lambda.envN}.csv'))
paste0("data/yuanghen_mod_data_newVars_", abund, ".rdata")
load(paste0("data/yuanghen_mod_data_newVars_", abund, ".rdata"))
abund = 'pa'		# 'qp','pa'  # is overwritten by data file loading.
paste0("data/yuanghen_mod_data_newVars_", abund, ".rdata")
file.path("results_sjSDM",paste0("tuning_YL_", abund),
glue::glue('manual_tuning_sjsdm_{period}_{trap}_{abund}_min{minocc}_{formula.env}_{date.model.run}.csv'))
setwd("C:/Users/55116479/Dropbox (Manchester Met)/R_online/Paraclaravis")
# passive surveys all years prior to 2005. - from Butchart et al 2018
eps.passive = c(0,	0.05)
pi.passive = c(0.10,	0.65)
pr.passive = c(0.40,	0.60)
pas.sur = c(eps.passive ,pi.passive,pr.passive)
pas.sur
# load ebird absences data
load("gis/ebird_absence_eps_prop.rdata")
yrRes <- data.frame(yrRes)
yrRes
pas.sur.tmp <- yrRes[,c("year", "prop.total")]
plot(yrRes[,c("year", "prop.total")])
## predict 5 years to 2030
lm1 <- lm(area ~ year, data = yrRes)
summary(lm1)
par(mfrow = c(2,2))
plot(lm1)
par(mfrow = c(1,1))
plot(yrRes$area ~ yrRes$year)
abline(lm1)
predict(lm1)
endYear <- 2030
prop21_30 <- predict(lm1, newdata = data.frame(year = 2021:2030))/1.74489e+11 # total area
pas.sur.tmp <- rbind(pas.sur.tmp, cbind(year = 2021:2030, prop.total = prop21_30))
signif(yrRes[,"prop.total"], 2)
floor(yrRes[,"prop.total"] * 10)/10
ceiling(yrRes[,"prop.total"] * 10)/10
# pas.sur.tmp
pas.sur05_20 <- cbind(year = pas.sur.tmp[,"year"],
eps_lower = floor(pas.sur.tmp[,"prop.total"] * 10)/10,
eps_upper = ceiling(pas.sur.tmp[,"prop.total"] * 10)/10,
pi_lower = rep(0.10,nrow(pas.sur.tmp)),
pi_upper = rep(0.65,nrow(pas.sur.tmp)),
pr_lower = rep(0.40,nrow(pas.sur.tmp)),
pr_upper = rep(0.60,nrow(pas.sur.tmp))
)
# rownames(pas.sur05_20) <- NULL
pas.sur05_20
# source functions
source("thompson_functions.r")
recordings <- read.csv("data/paraclaravis_All_data_specimens.csv", comment.char = "#")
dir()
dir("extinction risk")
setwd("C:/Users/55116479/Dropbox (Manchester Met)/R_online/Paraclaravis")
eps.passive = c(0,	0.05)
pi.passive = c(0.10,	0.65)
pr.passive = c(0.40,	0.60)
pas.sur = c(eps.passive ,pi.passive,pr.passive)
pas.sur
#  <- c("eps_lower","eps_upper","pi_lower", "pi_upper", "pr_lower", "pr_upper")
load("gis/ebird_absence_eps_prop.rdata")
yrRes <- data.frame(yrRes)
yrRes
pas.sur.tmp <- yrRes[,c("year", "prop.total")]
plot(yrRes[,c("year", "prop.total")])
lm1 <- lm(area ~ year, data = yrRes)
summary(lm1)
par(mfrow = c(2,2))
plot(lm1)
par(mfrow = c(1,1))
plot(yrRes$area ~ yrRes$year)
abline(lm1)
predict(lm1)
endYear <- 2030
prop21_30 <- predict(lm1, newdata = data.frame(year = 2021:2030))/1.74489e+11 # total area
pas.sur.tmp <- rbind(pas.sur.tmp, cbind(year = 2021:2030, prop.total = prop21_30))
signif(yrRes[,"prop.total"], 2)
floor(yrRes[,"prop.total"] * 10)/10
ceiling(yrRes[,"prop.total"] * 10)/10
# pas.sur.tmp
pas.sur05_20 <- cbind(year = pas.sur.tmp[,"year"],
eps_lower = floor(pas.sur.tmp[,"prop.total"] * 10)/10,
eps_upper = ceiling(pas.sur.tmp[,"prop.total"] * 10)/10,
pi_lower = rep(0.10,nrow(pas.sur.tmp)),
pi_upper = rep(0.65,nrow(pas.sur.tmp)),
pr_lower = rep(0.40,nrow(pas.sur.tmp)),
pr_upper = rep(0.60,nrow(pas.sur.tmp))
)
# rownames(pas.sur05_20) <- NULL
pas.sur05_20
# source functions
source("extinction risk/thompson_functions.r")
# load data files for recordings and surveys
# # setwd("C:/Users/e17889/Dropbox/Uni-Home/extinction risks/r-ext")
# setwd("~/Dropbox/Uni PhD/Extinction risks/r-ext")
# recordings <- read.csv("extinction risk/paraclaravis_butchart_data_recordings.csv")
# surveys <- read.csv("extinction risk/paraclaravis_butchart_data_surveys.csv")
recordings <- read.csv("extinction risk/paraclaravis_All_data_specimens.csv", comment.char = "#")
surveys <- read.csv("extinction risk/paraclaravis_All_data_surveys.csv", comment.char = "#")
head(recordings)
str(recordings)
recordings[,1:3]
#total number of years (including years without data)
# years = seq(min(recordings[,'year'],surveys[,'year']),max(recordings[,'year'],surveys[,'year']),by =1)
years = seq(min(recordings[,'year'],pas.sur05_20[,'year']),endYear,by =1) # if no surveys
Total.years = length(years)
#add passive surveys to the surveys (for each year without record or dedicated survey)
# years pre 2005
years.lt2005 <- years[years < 2005]
pas.sur.years.lt05 <- years.lt2005[!years.lt2005 %in% recordings[,1]] #find years without either surveys or recordings
pas.surveys.lt05 = cbind(pas.sur.years.lt05, t(replicate(length(pas.sur.years.lt05), pas.sur)))
# years >= 2005 (with ebird surveys)
years.gte2005 <- years[years >= 2005]
pas.sur.years.gte05 <- years.gte2005[!years.gte2005 %in% recordings[,1]] #find years without
pas.surveys.gte05 <- pas.sur05_20[pas.sur05_20[,"year"] %in% pas.sur.years.gte05,]
colnames(pas.surveys.lt05) <- colnames(pas.surveys.gte05)
# colnames(pas.surveys) = names(surveys)[-8] # without notes column
surveys = as.data.frame(rbind(pas.surveys.lt05, pas.surveys.gte05))
surveys <- surveys[order(surveys[,"year"]),]
rownames(surveys) <- NULL
head(surveys)
surveys
rec.year = cbind(recordings[,'year'],1) #whether a recording was made this year
rec.year = rbind(rec.year,cbind(surveys[,'year'],0))
# 0 for all unsuccessful surveys (if survey is successful, then it's  a record)
rec.year = rec.year[order(rec.year[,1]),]
rec.year
nrow(rec.year) == (nrow(recordings) + nrow(surveys))
(nrow(recordings) + nrow(surveys)) == length(years)
source("https://raw.githubusercontent.com/Cdevenish/R-Material/master/Functions/w.xls.r")
w.xls(cbind(surveys, rec.year))
rec.year
surveys
rec.year
