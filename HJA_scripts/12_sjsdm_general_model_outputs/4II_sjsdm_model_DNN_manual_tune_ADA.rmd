# Jan 18, 2021
# Jan 25, 2021
# code on sjsdm model run with DNN (for ADA cluster)



```{r setup}
# setwd('/media/yuanheng/SD-64g2/Downloads/backup2/HJA_analyses_Kelpie/HJA_scripts/12_sjsdm_general_model_outputs')
	
lapply(c('tidyverse','here','conflicted','reticulate','sjSDM','glue','vegan'), library, character.only=T)
	
conflict_prefer("filter", "dplyr")
conflict_prefer("select", "dplyr")
conflict_prefer('colSums', 'base')
	
here()
packageVersion('sjSDM')
#[1] ‘0.1.3.9000’
	

```


```{r set-names}
# ....... folder structure .......
# bioinfo structure
samtoolsfilter = "F2308" # F2308 filter only
samtoolsqual = "q48"
minimaprundate = 20200929
kelpierundate = 20200927
primer = "BF3BR2"
	
minocc = 5
abund = 'qp'		# 'qp','pa'  !!! change accordingly
trap <- "M1"; period = "S1"
date.model.run = 20210125   # !!! change accordingly
	
outputidxstatstabulatefolder = glue("outputs_minimap2_{minimaprundate}_{samtoolsfilter}_{samtoolsqual}_kelpie{kelpierundate}_{primer}_vsearch97")
outputpath = glue('../../Kelpie_maps/{outputidxstatstabulatefolder}')
	
sjsdmV = '0.1.3.9000' # package version
	
# names for graph
sjsdmVfolder = glue('sjsdm-{sjsdmV}')
	
```


```{r load-data}
# ..... load data ......
alldata = read.csv(here(outputpath, glue('sample_by_species_table_{samtoolsfilter}_minimap2_{minimaprundate}_kelpie{kelpierundate}_FSL_qp.csv')), header=T, sep=',', stringsAsFactors = F, na.strings='NA')
dim(alldata)
names(alldata)[1:10]
# 103
	
# roughness index
# from "Hmsc_CD/oregon_ada/data/demStats.rdata"
load(here('source','demStats.rdata'))
str(dem_stats)
	

```


```{r select subsets}
# ..... select trap, session .....
trap; period
	
alldata1 = subset(alldata, trap == "M1" & period == "S1")
dim(alldata1)
	
names(alldata1)[102:103]
	
a = alldata1 %>% select(contains('__'))
a = a[,which(specnumber(a, MARGIN=2)>=minocc)]
dim(a)
	
alldata1 = cbind(select(alldata1, -contains('__')), a)
dim(alldata1)
	
# ... 80% of data as training ...
# random selection
num.sample = dim(a)[1]
select.percent = .8
ssdd = 100 		# please keep this value to make results comparable!
set.seed(ssdd)
a = base::sample(1:num.sample, round(num.sample*select.percent))
	
# [1] 74 78 23 70  4 55 85  7 81 83 43 61 12 51 72 18 25  2 75 68 69 52 48 32 21
# [26] 27 39 57 16 11 67 71  6 29 45 30 53 79 86 31 33 49 82 28 47 41 87 42 24 80
# [51]  1  9 20 14 35 40  3 34 84 19 46 63 44 36 26  5 15 22 58 76
otu = select(alldata1, contains('__'))
otu.train = otu[a,]
dim(otu.train)
otu.test = otu[-a,]
	
envnames = c("insideHJA", "elevation_m", "canopyHeight_m", "minT_annual", "precipitation_mm", "distToRoad_m", "distToStream_m", "YrsSinceDist", "B1_20180717", "B2_20180717", "B3_20180717", "B4_20180717", "B5_20180717", "B6_20180717", "B7_20180717", "B10_20180717", "B11_20180717", "NDVI_20180717", "EVI_20180717", "B_20180717", "G_20180717", "W_20180717", "l_Cover_2m_max", "l_Cover_2m_4m", "l_Cover_4m_16m", "l_p25", "l_p95", "l_rumple")
	
ori.env = select(left_join(select(alldata1, envnames, "SiteName"), select(dem_stats, 'SiteName', 'tri.pt'), by=c('SiteName'='SiteName')), -'SiteName')
# add 'roughness' -> tri.pt
ori.env.train = ori.env[a,]
ori.env.test = ori.env[-a,]
str(ori.env.test)
	
ori.XY = select(alldata1, starts_with('UTM'))
ori.XY.train = ori.XY[a,]
ori.XY.test = ori.XY[-a,]
str(ori.XY.train)
	
# ... view data ...
par(mfrow=c(1,2))
hist(ori.env.train$elevation_m)
hist(ori.env$elevation_m)
	
ggplot(ori.XY, aes(UTM_E, UTM_N)) + geom_point() + geom_point(data=ori.XY.train, aes(colour='red')) + scale_colour_manual(labels = c('training'), values = c("red"))
	
```


```{r transform-data}
# 0/1
if (abund == 'pa')
{
	otu.train = as.data.frame((otu.train>0)*1)
	otu.test = as.data.frame((otu.test>0)*1)
}
	
# .. env data
scale.env.train.all = select(ori.env.train, -'insideHJA') %>% scale() 
str(scale.env.train.all)
	
scale.env.train = data.frame(scale.env.train.all) %>% add_column(insideHJA=as.factor(ori.env.train$insideHJA), .before=names(ori.env.train)[2])
str(scale.env.train)
	
dd.env.scaler = data.frame(t(data.frame(env.mean = attr(scale.env.train.all, "scaled:center"), env.sd = attr(scale.env.train.all, "scaled:scale"))))
str(dd.env.scaler)
	
rm(scale.env.train.all)
	
scale.env.test = as.data.frame(do.call(rbind, apply(select(ori.env.test, -'insideHJA'), 1, function(x){(x-dd.env.scaler['env.mean',])/dd.env.scaler['env.sd',]} ) )) %>% add_column(insideHJA=as.factor(ori.env.test$insideHJA), .before=names(ori.env.test)[2])
str(scale.env.test)
	
# .. spatial data
XY.train.all = scale(ori.XY.train)
str(XY.train.all)
	
XY.train = data.frame(XY.train.all)
str(XY.train)
	
dd.xy.scaler = data.frame(t(data.frame(sp.mean = attr(XY.train.all, "scaled:center"), sp.sd = attr(XY.train.all, "scaled:scale"))))
str(dd.xy.scaler)
base::rownames(dd.xy.scaler)
	
rm(XY.train.all)
	
XY.test = as.data.frame(do.call(rbind, apply(ori.XY.test, 1, function(x){(x-dd.xy.scaler['sp.mean',])/dd.xy.scaler['sp.sd',]} ) ))
str(XY.test)
	
# ... view data ...
par(mfrow=c(2,2))
hist(ori.env.train[,2],xlim=c(1000,5500), breaks = 10)
hist(ori.env.test[,2],xlim=c(1000,5500), breaks = 10)
hist(scale(ori.env.test[,2]))
hist(scale.env.test[,2])
	
par(mfrow=c(1,2))
hist(XY.test[,2])
hist(XY.train[,2])
	 
rm(dd.env.scaler, dd.xy.scaler)
	
```


```{r save data}
write.table(s.otu.train, file=here('source', glue('otu.train.{abund}.csv')), row.names=F, col.names=F, sep=',')
	
write.table(scale.env.train, file=here('source', 'scale.env.train.csv'), row.names=F, sep=',')
	
write.table(XY.train, file=here('source', 'scale.XY.train.csv'), row.names=F, sep=',')
	

```


```{r model-DNN.env}
# make sure input of sjsdm are numeric matrix
s.otu.train = as.matrix(otu.train)
attr(s.otu.train, 'dimnames') = NULL
str(s.otu.train)
	
names(scale.env.train)
	
# set variables
formula.env = 'envDNN'
lambda.env = seq(0,.3, length.out=4)	# .1
alpha.env = seq(.7,1, length.out=4)		# .9
lambda.sp = seq(0,1, length.out=7)	# .1
alpha.sp =  seq(0,1, length.out=7)	# .5 
hidden = list(c(50L,50L,10L), c(25L,25L,10L))
acti.sp = 'relu'
drop = seq(.1,.5, length.out=3) # .3
sample.bio = seq(0,1,length.out=11)
	

lambda.envN = 1		# 1,2,3,4 four jobs in AD
	
for (alpha.envN in 1:4) {
	for (lambda.spN in 1:7) {
		for (alpha.spN in 1:7) {
			for (dropN in 1:3) {
				for (hiddenN in 1:2) {
					
					lambda.bioN = sample(1:11,1)
					alpha.bioN = sample(1:11,1)
					print(c(lambda.envN, alpha.envN, lambda.spN, alpha.spN, dropN, hiddenN))
					
					model.train = sjSDM(Y = s.otu.train,
					  env = DNN(data=scale.env.train, formula = ~.,
					  hidden=hidden[[hiddenN]], lambda = lambda.env[lambda.envN], alpha = alpha.env[alpha.envN], activation=acti.sp, dropout=drop[dropN], bias=T),
					  
					  biotic = bioticStruct(lambda=sample.bio[lambda.bioN], alpha=sample.bio[alpha.bioN], on_diag=F, inverse = FALSE),
					  
					  spatial = linear(data=XY.train, ~0+UTM_E*UTM_N, lambda=lambda.sp[lambda.spN], alpha=alpha.sp[alpha.spN]),
					  
					  learning_rate = 0.003, # 0.003 recommended for high species number 
					  step_size = NULL, iter = 150L, family=stats::binomial('probit'), sampling = 5000L # 150L, 5000L
					 )
					 saveRDS(list(model=model.train, random=data.frame('lambda.bioN'=lambda.bioN, 'alpha.bioN'=alpha.bioN)), here(outputpath,'sjsdm_general_outputs',sjsdmVfolder,'sjsdm-model-RDS', glue('s-jSDM_tuning.model_{period}_{trap}_{abund}_min{minocc}_{formula.env}_lambdaE{lambda.envN}_{alpha.envN}_{lambda.spN}_{alpha.spN}_hidden{hiddenN}_{dropN}.RDS')) )
	
				}
			}
		}
	}
}
	

# ..... for test run .....
lambda.env = .1
alpha.env = .9
lambda.sp = .1
alpha.sp = .5 
hidden = c(25L,25L,10L)
acti.sp = 'relu'
drop = .3
	
model.train = sjSDM(Y = s.otu.train,
					  env = DNN(data=scale.env.train, formula = ~.,
					  hidden=hidden, lambda = lambda.env, alpha = alpha.env, activation=acti.sp, dropout=drop, bias=T),
					  
					  biotic = bioticStruct(lambda=lambda.sp, alpha=alpha.sp, on_diag=F, inverse = FALSE),
					  
					  spatial = linear(data=XY.train, ~0+UTM_E*UTM_N, lambda=lambda.sp, alpha=alpha.sp),
					  
					  learning_rate = 0.003, # 0.003 recommended for high species number 
					  step_size = NULL, iter = 5L, family=stats::binomial('probit'), sampling = 50L # 150L, 5000L
					 )
# ..... for test run .....
	
model.train = readRDS(here(tempsjsdmpath,'results','sjsdm-model-RDS', sjsdmVfolder, glue('s-jSDM_tuned.model_{period}_{trap}_{abund}_min{minocc}_{date.model.run}_{formula.env}.RDS')) )
	
plot(model.train$history)
	

```


```{r model-save-less}
#hiddenN=1; lambda.envN=2; alpha.envN=2; lambda.spN=2; alpha.spN=2;dropN=2

# set variables (from 'model-...' chunk)
tuning.dd = data.frame(lambda.env = numeric(), alpha.env = numeric(),  lambda.sp = numeric(), alpha.sp = numeric(), lambda.bio = numeric(), alpha.bio = numeric(), drop = numeric(), hidden = character(), loglike = numeric(), loss= numeric(), AUC.explain=numeric(), AUC.test=numeric())
	
lambda.envN = 1		# 1,2,3,4 four jobs in AD
hiddenN = 1			# 1,2 4*2 jobs
	
for (alpha.envN in 1:4) {
	for (lambda.spN in 1:7) {
		for (alpha.spN in 1:7) {
			for (dropN in 1:3) {
	
				lambda.bioN = sample(1:11,1)
				alpha.bioN = sample(1:11,1)
				
				model.train = sjSDM(Y = s.otu.train,
				  env = DNN(data=scale.env.train, formula = ~.,
				  hidden=hidden[[hiddenN]], lambda = lambda.env[lambda.envN], alpha = alpha.env[alpha.envN], activation=acti.sp, dropout=drop[dropN], bias=T),
				  
				  biotic = bioticStruct(lambda=sample.bio[lambda.bioN], alpha=sample.bio[alpha.bioN], on_diag=F, inverse = FALSE),
				  
				  spatial = linear(data=XY.train, ~0+UTM_E*UTM_N, lambda=lambda.sp[lambda.spN], alpha=alpha.sp[alpha.spN]),
				  
				  learning_rate = 0.003, # 0.003 recommended for high species number 
				  step_size = NULL, iter = 150L, family=stats::binomial('probit'), sampling = 5000L # 150L, 5000L
				)
				 
				tdd = data.frame(lambda.env = lambda.env[lambda.envN], alpha.env = alpha.env[alpha.envN], lambda.sp = lambda.sp[lambda.spN], alpha.sp = alpha.sp[alpha.spN], lambda.bio = sample.bio[lambda.bioN], alpha.bio = sample.bio[alpha.bioN], drop = drop[dropN], hidden = as.character(hiddenN), loglike = logLik(model.train), loss= model.train$history[length(model.train$history)], AUC.explain=.1, AUC.test=.1)
			
				for (pred in 1:2) {
				# 1 -> 'test'
					newdd = scale.env.test ; newsp = XY.test; otudd = otu.test
					if (pred==2) { newdd = NULL; newsp = NULL; otudd = otu.train }
					
					pred.dd = apply(abind::abind(lapply(1:3, function(i) predict(model.train, newdata=newdd, SP=newsp)) , along = -1L), 2:3, mean)
					attr(pred.dd, 'dimnames') = NULL
					
					if (pred==1) {
						otudd = rbind(otudd, count=(base::colSums(otudd)>0 & base::colSums(otudd)<dim(otudd)[1])*1 )
						pred.dd = pred.dd[ ,which(otudd[dim(otudd)[1],] == 1)]
						otudd = otudd[1:(dim(otudd)[1]-1), which(otudd[dim(otudd)[1],] == 1)]
					}
					
					otudd.pa = (otudd>0)*1
					roc.dd = lapply(1:dim(otudd)[2], function(i) roc(otudd.pa[,i], pred.dd[,i]))
					auc.mean = mean(as.numeric(sapply(lapply(roc.dd, function(i) str_split(auc(i), ':')), function(x) x[[1]][1] )))
					
					if (pred==2) {tdd$AUC.explain=auc.mean}
					if (pred==1) {tdd$AUC.test=auc.mean}
				}
			
				tuning.dd = rbind(tuning.dd, tdd)
				print(c(lambda.envN, alpha.envN, lambda.spN, alpha.spN, dropN))
			
				rm(model.train, tdd)
			
				write.table(tuning.dd, file=here(outputpath, 'sjsdm_general_outputs', sjsdmVfolder, 'DNN_tune', glue('manual_tuning.sjsdm_{period}_{trap}_{abund}_min{minocc}_{formula.env}_{date.model.run}.csv')), row.names=F, sep=',')
	
				 
			}
		}
	}
}
	

```

