# Multivariate abundance data
cbind(abund[1:6,2:4], head(X))
# Fit a predictive model using the manyglm function
fit = manyglm(abund ~ time + treatment, family='negative.binomial', data=X)
# Fit a Gaussian copula factor analytic model
fit.cord = cord(fit)
fit
plot(fit.cord)
summary(fit.cord)
# Multivariate abundance data
cbind(abund[1:6,2:4], head(X))
head(X)
summary(fit.cord)
head(X)
str(abund)
# Multivariate abundance data
cbind(abund[1:6,2:4], head(X))
summary(fit.cord)
fish = data.frame(matrix(nrow=2,ncol=34,dimnames = list(NULL, colnames(abund))))
fish[1:2,] = 1
fish[2, increasers] = 1.5
fish[2, decreasers] = 1/1.5
fish
fish = data.frame(matrix(nrow=2,ncol=34,dimnames = list(NULL, colnames(abund))))
fish
fish[1:2,] = 1
fish[2, increasers] = 1.5
fish[2, decreasers] = 1/1.5
increasers = c(
'Abudefduf.sp.', 'Acanthurus.nigrofuscus', 'Chromis.hypsilepis',
'Parma.microlepis', 'Pempheris.compressa', 'Scorpis.lineolatus',
'Trachinops.taeniatus'
)
decreasers = c(
'Aplodactylus.lophodon', 'Atypichthys.strigatus', 'Cheilodactylus.fuscus',
'Olisthops.cyanomelas', 'Pictilabrus.laticlavius'
)
fish[1:2,] = 1
fish[2, increasers] = 1.5
fish[2, decreasers] = 1/1.5
fish
plot(
1:34, fish[1,]
)
plot(
1:34, fish[1,],
type="l", ylim=c(0.6,1.6),
ylab="Proportion of mean abundances",
xlab = "", xaxt='n', col='blue',
main="Mean abundance proportions in restored sites relative to reference sites\nfor a specified effect size of 1.5"
)
lines(1:34, fish[2,], col='red',type='o')
legend(
"bottomright", legend=c("Ref", "Rest"), lty=c(1,1), title="", lwd = 1,
col=c("blue","red"), inset=0.01, box.lty = 0, y.intersp = 0.8, cex=0.8
)
text(
1:34,
par("usr")[3]-0.01,
srt = 50,
adj = 1,
xpd = TRUE,
labels = paste(colnames(fish)), cex = 0.65
)
# Generate matrix of effect sizes based on effect size of interest
effect_mat = effect_alt(fit, effect_size=1.5, increasers, decreasers, term='treatment')
effect_mat
# Perform a multivariate equivalence test
equivtest(fit.cord, coeffs=effect_mat)
# Load the reveg dataset
data(reveg, package="ecostats")
devtools::install_github('dwarton/ecostats')
# Load the reveg dataset
data(reveg, package="ecostats")
abund = mvabund(reveg$abund)
X = data.frame(treatment=reveg$treatment, pitfalls=reveg$pitfalls)
# Fit the null model
fit0 = manyglm(abund ~ 1 + offset(log(pitfalls)), family="negative.binomial", data=X)
fit0.cord = cord(fit0)
# Fit the alternative model
fit_reveg = manyglm(abund ~ treatment + offset(log(pitfalls)), family="negative.binomial", data=X)
fit_reveg.cord = cord(fit_reveg)
increasers = c(
'Acarina', 'Amphipoda', 'Araneae',
'Coleoptera', 'Collembola',
'Haplotaxida', 'Hemiptera', 'Hymenoptera',
'Isopoda'
)
decreasers = c('Blattodea', 'Tricladida')
# Generate matrix of effect sizes based on effect size of interest
effect_mat = effect_alt(fit_reveg, effect_size=5, increasers, decreasers, term='treatment')
# Perform the test
equivtest(fit_reveg.cord, effect_mat, object0=fit0.cord)
plot(function(x) dnorm(x), -5, 5,  main = "Probability density function", ylab = "P(x)")
title(sub = "Probability of a single value - can calculate probability between two values of x as area under curve")
X <- 2
xmin <- -5
xmax <- 5
plot(function(x) dnorm(x), xmin, xmax,  main = "Probability density function", ylab = "P(x)", type  = "n")
abline(v = -X, col = "red", lty = 2); abline(v = X, col = "red", lty = 2)
x <- seq(xmin, -X, 0.01); y <- (function(z) dnorm(z))(x)
coords <- cbind(x = c(x, -X), y = c(y, 0))
polygon(coords, density = 10, angle = 45, col = "blue")
x <- seq(X, xmax, 0.01); y <- (function(z) dnorm(z))(x)
coords <- cbind(x = c(x, X), y = c(y, 0))
polygon(coords, density = 10, angle = 45, col = "blue")
plot(function(x) dnorm(x), xmin, xmax,  main = "Probability density function", ylab = "P(x)", add = T)
## what is the probability of a value falling into one of the shaded areas?
(p1 <- pnorm(-X, lower.tail = T)) # P(x <= X), ie Probability of x being greater than -X above
(p2 <- pnorm(X, lower.tail = F)) # P(x >= X), ie Probability of x being less than X above
# therefore probability =  p1 + p2
(p <- p1 + p2)
text(-X, 0.05, labels = paste("Probability (area) =", round(p1, 3)), pos = 2)
text(X, 0.05, labels = paste("Probability (area) =", round(p2, 3)), pos = 4)
# Note that
pnorm(X, lower.tail = T) ==  1- pnorm(X, lower.tail = F)
# for above example,  probability of x <= -2 or x >= 2 is 0.0455. THis is two tailed, therefore probability for both tails
# therefore needs to be divided by two to get critical value of x
qnorm(p/2, lower.tail = T) # also need tail argument to specify which value of X,
# -2
qnorm(p/2, lower.tail = F)
pnorm(51, mean = 49, sd = 4.5, lower.tail = F)
pnorm(51, mean = 49, sd = 9/1.96, lower.tail = F)
pnorm(51, mean = 49, sd = 9/1.96, lower.tail = T)
plot(function(x) dnorm(x), -5, 5,  main = "Probability density function", ylab = "P(x)")
title(sub = "Probability between two values of x as area under curve")
X <- 2
xmin <- -5
xmax <- 5
plot(function(x) dnorm(x), xmin, xmax,  main = "Probability density function", ylab = "P(x)", type  = "n")
abline(v = -X, col = "red", lty = 2); abline(v = X, col = "red", lty = 2)
x <- seq(xmin, -X, 0.01); y <- (function(z) dnorm(z))(x)
coords <- cbind(x = c(x, -X), y = c(y, 0))
polygon(coords, density = 10, angle = 45, col = "blue")
x <- seq(X, xmax, 0.01); y <- (function(z) dnorm(z))(x)
coords <- cbind(x = c(x, X), y = c(y, 0))
polygon(coords, density = 10, angle = 45, col = "blue")
plot(function(x) dnorm(x), xmin, xmax,  main = "Probability density function", ylab = "P(x)", add = T)
## what is the probability of a value falling into one of the shaded areas?
(p1 <- pnorm(-X, lower.tail = T)) # P(x <= X), ie Probability of x being greater than -X above
(p2 <- pnorm(X, lower.tail = F)) # P(x >= X), ie Probability of x being less than X above
# therefore probability =  p1 + p2
(p <- p1 + p2)
text(-X, 0.05, labels = paste("Probability (area) =", round(p1, 3)), pos = 2)
text(X, 0.05, labels = paste("Probability (area) =", round(p2, 3)), pos = 4)
# Note that
pnorm(X, lower.tail = T) ==  1- pnorm(X, lower.tail = F)
plot(function(x) pnorm(x), xmin, xmax,  main = "Normal Cumulative", ylab = "P(X \U2264 x)")
lines(c(xmin-1, X, X), c(1-p1, 1-p1, -0.1), col = "red", lty = 2)
lines(c(xmin-1, -X, -X), c(p1, p1, -0.1), col = "red", lty = 2)
title(sub = "Y axis shows probability of obtaining x or less")
function(x) pnorm(x)
qnorm(0.95)
qnorm(0.95/2)
qnorm(1-0.95/2)
0.95/2
## eg for z score for 2 standard deviations
qnorm(0.95, lower.tail = T)
## eg for z score for 2 standard deviations
qnorm(0.99, lower.tail = T)
0.95+(1-0.95)/2
## eg for z score for 2 standard deviations
qnorm(0.95+(1-0.95)/2, lower.tail = T) ## ie its' the 97.5 quantile of the standard normal distribution
## eg for z score for 2 standard deviations
qnorm(0.95+(1-0.95)/2, lower.tail = F) ## ie its' the 97.5 quantile of the standard normal distribution
## eg for z score for 2 standard deviations
qnorm(0.95+(1-0.95)/2, lower.tail = T) ## ie its' the 97.5 quantile of the standard normal distribution
0.95+(1-0.95)/2
z <- qnorm(ci+(1-ci)/2, lower.tail = T) ## ie its' the 97.5 quantile of the standard normal distribution
ci <- 0.95
z <- qnorm(ci+(1-ci)/2, lower.tail = T) ## ie its' the 97.5 quantile of the standard normal distribution
((moe/z)^2)/sd
moe <- 0.2
((moe/z)^2)/sd
sd <- 1
((moe/z)^2)/sd
((moe/z)^2)/sd^2
0.98/sqrt(1013)
((moe/z)^2)* 1/sd^2
((moe/z)^2)* 1/sd^2
((moe/z)^2)* 1/(sd^2)
(0.31/1.96)^2 * 1/0.25
(0.031/1.96)^2 * 1/0.25
1/((moe/z)^2)* 1/(sd^2))
1/(((moe/z)^2)* 1/(sd^2))
1.96
1/(((moe/z)^2)* 1/(sd^2))
moe <- 0.0.31
z <- qnorm(ci+(1-ci)/2, lower.tail = T) ## ie its' the 97.5 quantile of the standard normal distribution
sd <- 0.25
1/(((moe/z)^2)* 1/(sd^2))
1/(((moe/z)^2)* 1/(sd))
0.5/100
sd/(moe/z)^2
moe <-0.031
z <- 1.96 # ie approx 2 sd
sd <- 0.25
sd/(moe/z)^2
1/(((moe/z)^2)* 1/(sd))
moe <- 1.96*
z <- 1.96 # ie approx 2 sd
moe <- 1.96*sqrt(0.25/1013)
sd/(moe/z)^2
var <- 0.2^2
# n =
var/(moe/z)^2
var <- 0.25
moe <- 0.02
ci <- 0.95
z <- qnorm(ci+(1-ci)/2, lower.tail = T) ## ie its' the 97.5 quantile of the standard normal distribution
var <- 0.25
# n =
var/(moe/z)^2
set.seed(999)
x <- rnorm(100, 15, 3)
# set se at some relative value
se = .05*mean(x)
# set se at some relative value
# eg 1/4 of mean
frac <- 1/4
se = frac*mean(x)
# then n >=
var(x)/((frac*mean(x))^2)
# then n >=
var(x)/se^2
x <- rnorm(100, 15, 3)
x <- rnorm(100, 15, 3)
# set se at some relative value
# eg 1/4 of mean
frac <- 1/4
se = frac*mean(x)
# then n >=
var(x)/se^2
# set se at some relative value
# eg 1/4 of mean
frac <- 0.05
se = frac*mean(x)
# then n >=
var(x)/se^2
# then n >=
n <- var(x)/se^2
1:floor(n)+5
plot(1:(floor(n)+5))
plot(1:(floor(n)+5), seq_along((floor(n)+5))
)
seq_along((floor(n)+5))
plot(1:(floor(n)+5), seq_len((floor(n)+5)))
plot(1:(floor(n)+5), seq_len((floor(n)+5)), type = "n", xlab = "n", ylab = var)
plot(1:(floor(n)+5), seq_len((floor(n)+5)), type = "n", xlab = "n", ylab = "var")
ntot <- floor(n)+5
nn <- floor(n)+5
set.seed(999)
mean <- 15
sd <- 3
x <- rnorm(100, mean, sd)
# set se at some relative value
# eg 1/4 of mean
frac <- 0.05
se = frac*mean(x)
# then n >=
n <- var(x)/se^2
nn <- floor(n)+5
var_nn <- sapply(1:nn, function(x) var(rnorm(x, mean, sd)))
var_nn <- sapply(2:nn, function(x) var(rnorm(x, mean, sd)))
seq_len(nn)
plot(seq_len(nn), max(var_nn), type = "n", xlab = "n", ylab = "var")
plot(seq_len(nn), type = "n", xlab = "n", ylab = "var", ylim = c(0, max(var_nn)))
points(2:nn, var_nn, type = "l")
abline(v = floor(n))
# set se at some relative value
# eg 1/4 of mean
frac <- 0.02
se = frac*mean(x)
# then n >=
n <- var(x)/se^2
nn <- floor(n)+5
var_nn <- sapply(2:nn, function(x) var(rnorm(x, mean, sd)))
plot(seq_len(nn), type = "n", xlab = "n", ylab = "var", ylim = c(0, max(var_nn)))
points(2:nn, var_nn, type = "l")
abline(v = floor(n))
se
se_nn <- sapply(2:nn, function(x) sqrt(var(rnorm(x, mean, sd))/x))
plot(seq_len(nn), type = "n", xlab = "n", ylab = "var", ylim = c(0, max(se_nn)))
points(2:nn, se_nn, type = "l")
abline(v = floor(n))
frac <- 0.05
se = frac*mean(x)
# then n >=
n <- var(x)/se^2
nn <- floor(n)+5
var_nn <- sapply(2:nn, function(x) var(rnorm(x, mean, sd)))
se_nn <- sapply(2:nn, function(x) sqrt(var(rnorm(x, mean, sd))/x))
plot(seq_len(nn), type = "n", xlab = "n", ylab = "var", ylim = c(0, max(var_nn)))
points(2:nn, var_nn, type = "l")
abline(v = floor(n))
plot(seq_len(nn), type = "n", xlab = "n", ylab = "var", ylim = c(0, max(se_nn)))
points(2:nn, se_nn, type = "l")
abline(v = floor(n))
# set se at some relative value
# eg 1/4 of mean
frac <- 0.02
# frac <- 0.05
se = frac*mean(x)
# then n >=
n <- var(x)/se^2
nn <- floor(n)+5
var_nn <- sapply(2:nn, function(x) var(rnorm(x, mean, sd)))
se_nn <- sapply(2:nn, function(x) sqrt(var(rnorm(x, mean, sd))/x))
plot(seq_len(nn), type = "n", xlab = "n", ylab = "var", ylim = c(0, max(var_nn)))
points(2:nn, var_nn, type = "l")
abline(v = floor(n))
plot(seq_len(nn), type = "n", xlab = "n", ylab = "var", ylim = c(0, max(se_nn)))
points(2:nn, se_nn, type = "l")
abline(v = floor(n))
plot(seq_len(nn), type = "n", xlab = "n", ylab = "se", ylim = c(0, max(se_nn)))
points(2:nn, se_nn, type = "l")
abline(v = floor(n))
abline(h = se)
se_nn <- sapply(2:nn, function(x) sqrt(var(rnorm(x, mean, sd))/x))
plot(seq_len(nn), type = "n", xlab = "n", ylab = "se", ylim = c(0, max(se_nn)))
points(2:nn, se_nn, type = "l")
abline(v = floor(n))
abline(h = se)
library(vegan)
install.packages("vegan")
library(vegan)
head(dune)
data(dune)
head(duen)
data(dune)
head(dune)
install_github("nsj3/darleq3", build_vignettes=TRUE)
devtools::install_github("nsj3/darleq3", build_vignettes=TRUE)
library(darleq3)
fn <- system.file("extdata/DARLEQ2TestData.xlsx", package="darleq3")
shell.exec(fn)
f <- 50
rStack.agg <- raster::aggregate(rStack.cl, f)
rStack.agg
# load package
library(raster)
library(prioritizr)
utm10N <- 32610 # epsg code utm 30 N
parallel::detectCores()
resFolder <-  "J:/UEA/gitHRepos/HJA_analyses_Kelpie/Hmsc_CD/oregon_ada/code_sjSDM/r20210716b/results"
gis_out <- "J:/UEA/gitHRepos/HJA_analyses_Kelpie/Hmsc_CD/oregon_ada/data/gis"
load(file.path(resFolder, "rasterStacks_cl.rdata")) # rStack.cl
load(file.path(gis_out, "hja_raster.rdata")) # hja.r
## load templates
load(file.path(gis_out, "templateRaster.rdata")) ## r.msk, indNA aoi.pred.sf, r.aoi.pred - reduced area for plotting
r.aoi.pred
freq(r.aoi.pred)
plot(r.aoi.pred)
(ncell(r.aoi.pred) * (30*30) ) / 1000000
250624* (30*30)  / 1000000 ## study area
ogsi <- raster("J:/UEA/Oregon/gis/marie/ogsi_2012_smoothed.tif")
plot(ogsi)
ogsi.utm <- projectRaster(ogsi, hja.r, method = "ngb") # % values
ogsi.utm <- mask(ogsi.utm, hja.r)
ogsi.utm
plot(ogsi.utm)
# f <- 3
# f <- 5
f <- 10
f <- 50
rStack.agg <- raster::aggregate(rStack.cl, f)
rStack.agg
plot(rStack.agg, 1)
# ## reduced data set
# template:
r <- aggregate(r.aoi.pred, f)
r
plot(r)
freq(r)
ogsi.agg <- aggregate(ogsi.utm, f)
plot(ogsi.agg, colNA = "black")
sum(!is.na(values(ogsi.agg)))
p1 <- problem(r, rStack.agg[[1:10]])
p4 <- problem(ogsi.agg, rStack.agg[[1:10]]) %>%
add_min_set_objective() %>%
add_relative_targets(0.50) %>% # 50% of abundance of each species
# add_neighbor_constraints(2) %>%
add_boundary_penalties(penalty = 100, edge_factor = 0.5) %>%
add_binary_decisions() %>%
add_cbc_solver(gap = 0.5)
p4
s4 <- solve(p4)
plot(s4)
p4 <- problem(ogsi.agg, rStack.agg[[1:10]]) %>%
add_min_set_objective() %>%
add_relative_targets(0.25) %>% # 50% of abundance of each species
# add_neighbor_constraints(2) %>%
add_boundary_penalties(penalty = 100, edge_factor = 0.5) %>%
add_binary_decisions() %>%
add_cbc_solver(gap = 0.1)
s4 <- solve(p4)
plot(s4)
p4 <- problem(ogsi.agg, rStack.agg[[1:10]]) %>%
add_min_set_objective() %>%
add_relative_targets(0.25) %>% # 50% of abundance of each species
# add_neighbor_constraints(2) %>%
add_boundary_penalties(penalty = 0, edge_factor = 0.5) %>%
add_binary_decisions() %>%
add_cbc_solver(gap = 0.1)
p4
s4 <- solve(p4)
plot(s4)
p4 <- problem(ogsi.agg, rStack.agg[[1:10]]) %>%
add_min_set_objective() %>%
add_relative_targets(0.25) %>% # 50% of abundance of each species
# add_neighbor_constraints(2) %>%
add_boundary_penalties(penalty = 1, edge_factor = 0.5) %>%
add_binary_decisions() %>%
add_cbc_solver(gap = 0.1)
p4
s4 <- solve(p4)
plot(s4)
p4 <- problem(ogsi.agg, rStack.agg[[1:10]]) %>%
add_min_set_objective() %>%
add_relative_targets(0.25) %>% # 50% of abundance of each species
# add_neighbor_constraints(2) %>%
add_boundary_penalties(penalty = 0.5, edge_factor = 0.5) %>%
add_binary_decisions() %>%
add_cbc_solver(gap = 0.1)
p4
s4 <- solve(p4)
# issue with parallel in above solver, also try this.
remotes::install_bioc("lpsymphony")
# issue with parallel in above solver, also try this.
remotes::install_bioc("lpsymphony")
# issue with parallel in above solver, also try this.
remotes::install_bioc("lpsymphony")
library(lpsymphony)
setwd("J:/UEA/gitHRepos/HJA_analyses_Kelpie/Hmsc_CD/oregon_ada")
library(dplyr)
library(rgdal)
library(raster)
library(sf)
library(ggplot2)
utm10N <- 32610
## on ADA
gis_out <- gis_in <- "data/gis"
baseFolder <- "code_sjSDM/r20210716b"
resFolder <- file.path(baseFolder, "results")
plotsFolder <- file.path(baseFolder, "plots")
# load model data - for species classification
load(file.path(resFolder, paste0("modelData_",abund,".rdata")))
rm(env.vars, k, noSteps, vars, device, iter, sampling, otuenv)
resFolder <- file.path(baseFolder, "results")
plotsFolder <- file.path(baseFolder, "plots")
if(!dir.exists(plotsFolder)) dir.create(plotsFolder, recursive = TRUE)
abund <- "pa"
# load model data - for species classification
load(file.path(resFolder, paste0("modelData_",abund,".rdata")))
rm(env.vars, k, noSteps, vars, device, iter, sampling, otuenv)
## load species AUC resutls for filtering
load(file.path(resFolder, "sp_test_results.rdata")) # eval.results, sp.res.test, sp.res.train
## Mean AUC per species (and other eval metrics)
str(sp.res.test, max.level = 1)
head(sp.res.test$auc)
sum(is.na(sp.res.test$auc))
## Filter species by auc
auc.filt <- 0.70
sum(sp.res.test$auc >= auc.filt, na.rm = T) # 88
# What is incidence of species in test set?
hist(colSums(otu.pa.csv.test))
hist(colSums(otu.pa.csv)) # train set
sum(colSums(otu.pa.csv.test) > 1)
# What is incidence of test data
table(colSums(otu.pa.csv.test))
sum(colSums(otu.pa.csv.test) ==0) # 17 not represented
plot(colSums(otu.pa.csv.test), sp.res.test$auc)
test.incidence <- data.frame(species = colnames(otu.pa.csv.test), test.noSites = colSums(otu.pa.csv.test),
test.incid = colSums(otu.pa.csv.test)/nrow(otu.pa.csv.test), row.names = NULL)
head(test.incidence)
# how many species are included?
(88+17) / ncol(otu.pa.csv.test)
# ## extract species over AUC filter
# str(pred.sp, max.level = 1)
# incidence
incidence <- colSums(otu.pa.csv)/nrow(otu.pa.csv)
spp <- data.frame(species = colnames(get(paste0("otu.", abund, ".csv")))) %>%
tidyr::separate(col = species, into = c("OTU", "empty", "class", "order", "family",
"genus", "epithet", "BOLD", "BOLDID",
"size"),
remove = FALSE, sep = "_", convert = TRUE) %>%  ## creates real NAs with convert = T
mutate(best.name = case_when(is.na(epithet) & is.na(genus) & is.na(family) & is.na(order) ~ class,
is.na(epithet) & is.na(genus) & is.na(family) ~ order,
is.na(epithet) & is.na(genus) ~ family,
is.na(epithet) ~ genus,
TRUE ~ paste(genus, epithet, sep = "_")
)) %>%
dplyr::select(-empty)%>%
mutate(auc = sp.res.test$auc,
tjur = sp.res.test$tjur,
incidence = incidence,
best.name = paste(best.name, BOLDID, sep = "_"))%>%
left_join(y = test.incidence, by = "species")
head(spp)
sum(is.na(spp$best.name))
sum(grepl("NA_NA", spp$best.name))
head(spp, 30)
## check relationship of incidence and tjur
# plot(spp$incidence, spp$tjur)
cor.test(spp$incidence, spp$tjur)
cor.test(spp$incidence, spp$auc)
plot(spp$incidence, spp$tjur)
plot(spp$test.incid, spp$tjur)
plot(spp$incidence, spp$auc)
plot(spp$incidence, spp$tjur)
# What is incidence of test data
table(colSums(otu.pa.csv.test))
