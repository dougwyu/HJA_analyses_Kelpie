kelpierundate,
"_FSL_qp.csv")
# file path:
fn <- file.path(gitHub, outputidxstatstabulatefolder, datFile)
# what file am i using?
basename(fn)
# when was it modified? - only if stored locally.
file.mtime(fn)
# read complete data set
otuenv <- read.csv(fn, stringsAsFactors = FALSE, na.strings = "NA")
# keep OTUs with >= minocc incidences AND with presnece at both M1 or M2
minocc <- 6 # set to high number (e.g. 20) for testing
## get Species columns by M1 and M2, with minocc calculated per trap
spM <- otuenv %>%
dplyr::filter(period == "S1") %>%
dplyr::select(SiteName, trap, contains("__")) %>%
tidyr::pivot_longer(cols = contains("__"), names_to = "OTU", values_drop_na = FALSE) %>%
mutate(value = value>0) %>% # change to PA
group_by(OTU, trap) %>%
summarise(nSites = sum(value, na.rm = T)) %>% # Number of sites at which present
filter(nSites >= minocc) %>% # filter by minocc
ungroup() %>%
tidyr::pivot_wider(names_from = trap, values_from = nSites, values_fn = function(x) sum(x)>0) %>%
filter(M1) %>% # CHOOOSE HERE FOR SINGLE. OR SHARED TRAP SPECIES GFROUP: filter(M1 & M2)
select(OTU)
# filter species here to those in sp.M1m2$OTU - already filtered for minocc
otu.qp.csv <- otuenv %>%
dplyr::filter(period == "S1" & trap == "M1") %>%
dplyr::select(spM$OTU) ##
# convert to presence/absence data
otu.pa.csv <- otu.qp.csv
otu.pa.csv[otu.pa.csv > 0] <- 1
min(colSums(otu.pa.csv)) >= minocc # should be TRUE
# clean up
rm(datFile, gitHub, kelpierundate, minimaprundate, outputidxstatstabulatefolder, primer, samtoolsfilter, samtoolsqual, fn, spM)
# remove OTUs, XY, and normalised NDVI and EVI
# average, optionally log, select, and scale env covariates
env.vars <- otuenv %>%
dplyr::filter(period == "S1" & trap == "M1") %>%
dplyr::select(!contains("__"), UTM_E, UTM_N, -starts_with("nor")) %>%
mutate(uniqueID = paste(SiteName, trap, period, sep = "_"),
elevation_m = elevation_f * 0.3048, ## convert to metres
canopyHeight_m = canopyHeight_f * 0.3048,
B1_median = apply(across(starts_with("B1_")), 1, median),
B2_median = apply(across(starts_with("B2_")), 1, median),
B3_median = apply(across(starts_with("B3_")), 1, median),
B4_median = apply(across(starts_with("B4_")), 1, median),
B5_median = apply(across(starts_with("B5_")), 1, median),
B6_median = apply(across(starts_with("B6_")), 1, median),
B7_median = apply(across(starts_with("B7_")), 1, median),
B10_median = apply(across(starts_with("B10_")), 1, median),
B11_median = apply(across(starts_with("B11_")), 1, median),
lg_DistStream = log(distToStream_m + 0.001),
lg_DistRoad = log(distToRoad_m + 0.001),
lg_YrsDisturb = log(YrsSinceDist + 0.001),
lg_cover2m_max = log(l_Cover_2m_max + 0.001),
lg_cover2m_4m = log(l_Cover_2m_4m + 0.001),
lg_cover4m_16m = log(l_Cover_4m_16m + 0.001)) %>%
mutate(
clearcut = factor(clearcut),
insideHJA = factor(insideHJA))
# str(env.vars)
# head(env.vars)
# load new variables
load("data/ann_topo.df")
sapply(ann.topo, function(x) sum(is.na(x)))
colnames(ann.topo)
##  merge with env.vars
env.vars <- dplyr::left_join(env.vars, ann.topo, by = "SiteName")
# summary(env.vars)
env.vars$tpi <- as.factor(env.vars$tpi)
# str(env.vars)
# old vars
# oldVars <- c("insideHJA", "elevation_f", "canopyHeight_f", "minT_annual", "precipitation_mm", "distToRoad_m", "distToStream_m", "YrsSinceDist", "B1_20180717", "B2_20180717", "B3_20180717", "B4_20180717", "B5_20180717", "B6_20180717", "B7_20180717", "B10_20180717", "B11_20180717", "NDVI_20180717", "EVI_20180717", "B_20180717", "G_20180717", "W_20180717", "l_Cover_2m_max", "l_Cover_2m_4m", "l_Cover_4m_16m", "l_p25", "l_p95", "l_rumple")
#
# # new vars
# newvars <- c("be10", "tri", "slope", "Nss", "Ess", "ht", "ht.r250", "ht.r500", "ht.r1k", "cov2_4", "cov2_4.r250", "cov2_4.r500", "cov2_4.r1k", "cov4_16", "cov4_16.r250", "cov4_16.r500", "cov4_16.r1k", "be500", "mTopo", "cut.r1k.pt", "insideHJA", "minT_annual", "maxT_annual", "precipitation_mm", "lg_DistStream", "lg_DistRoad", "lg_YrsDisturb", "B1_20180717", "B2_20180717", "B3_20180717", "B4_20180717", "B5_20180717", "B6_20180717", "B7_20180717", "B10_20180717", "B11_20180717", "NDVI_20180717", "EVI_20180717", "B_20180717", "G_20180717", "W_20180717", "l_p25", "l_rumple")
varsName <- "vars3"
vars <- c("be10", "slope", "tri", "Nss", "Ess","ndmi_stdDev", "ndvi_p5", "ndvi_p50", "ndvi_p95", "ndmi_p5", "ndmi_p50", "ndmi_p95", "savi_p50", "LC08_045029_20180726_B1", "LC08_045029_20180726_B3", "LC08_045029_20180726_B4", "LC08_045029_20180726_B5", "LC08_045029_20180726_B7", "LC08_045029_20180726_B10", "ndmi_stdDev_100m", "ndvi_p5_100m", "ndvi_p50_100m", "ndvi_p95_100m", "ndmi_p5_100m", "ndmi_p50_100m", "ndmi_p95_100m", "savi_p50_100m", "LC08_045029_20180726_B1_100m", "LC08_045029_20180726_B3_100m", "LC08_045029_20180726_B4_100m", "LC08_045029_20180726_B5_100m", "LC08_045029_20180726_B7_100m", "LC08_045029_20180726_B10_100m", "tpi250",  "tpi500", "tpi1k" , "ht", "ht.r250", "ht.r1k", "cov2_4.r250", "cov2_4.r1k", "cov4_16", "cov4_16.r250", "cov4_16.r1k", "mTopo", "cut.r1k.pt", "insideHJA", "lg_DistStream", "lg_DistRoad", "lg_YrsDisturb", "l_p25", "l_rumple")
## two points not covered by tpi and tri
indNA <- complete.cases(env.vars[,vars])
sum(indNA)
env.vars <- env.vars[indNA,]
otu.pa.csv <- otu.pa.csv[indNA,]
otu.qp.csv <- otu.qp.csv[indNA,]
rm(indNA)
# colnames(env.vars)
## Save model data
save(otu.pa.csv, otu.qp.csv, otuenv, env.vars,
k, minocc, noSteps, vars, varsName, abund, device, iter, sampling,
file = file.path(resFolder, "modelData.rdata"))
resFolder <-"code_sjSDM/r20210319a/results"
if(!dir.exists(resFolder)) dir.create(resFolder, recursive = TRUE)
## Updated to new vars, also changes to elevation_m, canopy_height_m  to _f.
# # model settings:
abund <- "pa"
spChoose <- "M1"
device <- "gpu"
iter <- 150L
sampling <- 5000L
## Number of samples from tuning grid - random search
noSteps <- 1500
# no of CV folds
k <- 5
# timings...
# models take approx to 0.28 mins run (Run time 00:36:11 for 125 models)
# noSteps * k * 0.28/60
noSteps * k
# Storage
# About ~600k per model .rds -- in GB
# noSteps * k * 600  / 1048576
# for testing on cpu
# device <- "cpu"
# iter <- 10L
# sampling <- 100L
# noSteps <- 5
# k <- 3
### 1. Get data from github #####
samtoolsfilter <- "F2308" # F2308 filter only
samtoolsqual <- "q48"
minimaprundate <- 20200929
kelpierundate <- 20200927
primer <- "BF3BR2"
gitHub <- "https://raw.githubusercontent.com/dougwyu/HJA_analyses_Kelpie/master/Kelpie_maps"
outputidxstatstabulatefolder <- paste0("outputs_minimap2_",
minimaprundate,"_",
samtoolsfilter,"_",
samtoolsqual,
"_kelpie",
kelpierundate,
"_",
primer,
"_vsearch97")
datFile <- paste0("sample_by_species_table_",
samtoolsfilter,
"_minimap2_",
minimaprundate,
"_kelpie",
kelpierundate,
"_FSL_qp.csv")
# file path:
fn <- file.path(gitHub, outputidxstatstabulatefolder, datFile)
# what file am i using?
basename(fn)
# when was it modified? - only if stored locally.
file.mtime(fn)
# read complete data set
otuenv <- read.csv(fn, stringsAsFactors = FALSE, na.strings = "NA")
# keep OTUs with >= minocc incidences AND with presnece at both M1 or M2
minocc <- 6 # set to high number (e.g. 20) for testing
## get Species columns by M1 and M2, with minocc calculated per trap
spM <- otuenv %>%
dplyr::filter(period == "S1") %>%
dplyr::select(SiteName, trap, contains("__")) %>%
tidyr::pivot_longer(cols = contains("__"), names_to = "OTU", values_drop_na = FALSE) %>%
mutate(value = value>0) %>% # change to PA
group_by(OTU, trap) %>%
summarise(nSites = sum(value, na.rm = T)) %>% # Number of sites at which present
filter(nSites >= minocc) %>% # filter by minocc
ungroup() %>%
tidyr::pivot_wider(names_from = trap, values_from = nSites, values_fn = function(x) sum(x)>0) %>%
filter(M1) %>% # CHOOOSE HERE FOR SINGLE. OR SHARED TRAP SPECIES GFROUP: filter(M1 & M2)
select(OTU)
# filter species here to those in sp.M1m2$OTU - already filtered for minocc
otu.qp.csv <- otuenv %>%
dplyr::filter(period == "S1" & trap == "M1") %>%
dplyr::select(spM$OTU) ##
# convert to presence/absence data
otu.pa.csv <- otu.qp.csv
otu.pa.csv[otu.pa.csv > 0] <- 1
min(colSums(otu.pa.csv)) >= minocc # should be TRUE
# clean up
rm(datFile, gitHub, kelpierundate, minimaprundate, outputidxstatstabulatefolder, primer, samtoolsfilter, samtoolsqual, fn, spM)
# remove OTUs, XY, and normalised NDVI and EVI
# average, optionally log, select, and scale env covariates
env.vars <- otuenv %>%
dplyr::filter(period == "S1" & trap == "M1") %>%
dplyr::select(!contains("__"), UTM_E, UTM_N, -starts_with("nor")) %>%
mutate(uniqueID = paste(SiteName, trap, period, sep = "_"),
elevation_m = elevation_f * 0.3048, ## convert to metres
canopyHeight_m = canopyHeight_f * 0.3048,
B1_median = apply(across(starts_with("B1_")), 1, median),
B2_median = apply(across(starts_with("B2_")), 1, median),
B3_median = apply(across(starts_with("B3_")), 1, median),
B4_median = apply(across(starts_with("B4_")), 1, median),
B5_median = apply(across(starts_with("B5_")), 1, median),
B6_median = apply(across(starts_with("B6_")), 1, median),
B7_median = apply(across(starts_with("B7_")), 1, median),
B10_median = apply(across(starts_with("B10_")), 1, median),
B11_median = apply(across(starts_with("B11_")), 1, median),
lg_DistStream = log(distToStream_m + 0.001),
lg_DistRoad = log(distToRoad_m + 0.001),
lg_YrsDisturb = log(YrsSinceDist + 0.001),
lg_cover2m_max = log(l_Cover_2m_max + 0.001),
lg_cover2m_4m = log(l_Cover_2m_4m + 0.001),
lg_cover4m_16m = log(l_Cover_4m_16m + 0.001)) %>%
mutate(
clearcut = factor(clearcut),
insideHJA = factor(insideHJA))
# str(env.vars)
# head(env.vars)
# load new variables
load("data/ann_topo.df")
sapply(ann.topo, function(x) sum(is.na(x)))
colnames(ann.topo)
##  merge with env.vars
env.vars <- dplyr::left_join(env.vars, ann.topo, by = "SiteName")
# summary(env.vars)
env.vars$tpi <- as.factor(env.vars$tpi)
# str(env.vars)
# old vars
# oldVars <- c("insideHJA", "elevation_f", "canopyHeight_f", "minT_annual", "precipitation_mm", "distToRoad_m", "distToStream_m", "YrsSinceDist", "B1_20180717", "B2_20180717", "B3_20180717", "B4_20180717", "B5_20180717", "B6_20180717", "B7_20180717", "B10_20180717", "B11_20180717", "NDVI_20180717", "EVI_20180717", "B_20180717", "G_20180717", "W_20180717", "l_Cover_2m_max", "l_Cover_2m_4m", "l_Cover_4m_16m", "l_p25", "l_p95", "l_rumple")
#
# # new vars
# newvars <- c("be10", "tri", "slope", "Nss", "Ess", "ht", "ht.r250", "ht.r500", "ht.r1k", "cov2_4", "cov2_4.r250", "cov2_4.r500", "cov2_4.r1k", "cov4_16", "cov4_16.r250", "cov4_16.r500", "cov4_16.r1k", "be500", "mTopo", "cut.r1k.pt", "insideHJA", "minT_annual", "maxT_annual", "precipitation_mm", "lg_DistStream", "lg_DistRoad", "lg_YrsDisturb", "B1_20180717", "B2_20180717", "B3_20180717", "B4_20180717", "B5_20180717", "B6_20180717", "B7_20180717", "B10_20180717", "B11_20180717", "NDVI_20180717", "EVI_20180717", "B_20180717", "G_20180717", "W_20180717", "l_p25", "l_rumple")
varsName <- "vars3"
vars <- c("be10", "slope", "tri", "Nss", "Ess","ndmi_stdDev", "ndvi_p5", "ndvi_p50", "ndvi_p95", "ndmi_p5", "ndmi_p50", "ndmi_p95", "savi_p50", "LC08_045029_20180726_B1", "LC08_045029_20180726_B3", "LC08_045029_20180726_B4", "LC08_045029_20180726_B5", "LC08_045029_20180726_B7", "LC08_045029_20180726_B10", "ndmi_stdDev_100m", "ndvi_p5_100m", "ndvi_p50_100m", "ndvi_p95_100m", "ndmi_p5_100m", "ndmi_p50_100m", "ndmi_p95_100m", "savi_p50_100m", "LC08_045029_20180726_B1_100m", "LC08_045029_20180726_B3_100m", "LC08_045029_20180726_B4_100m", "LC08_045029_20180726_B5_100m", "LC08_045029_20180726_B7_100m", "LC08_045029_20180726_B10_100m", "tpi250",  "tpi500", "tpi1k" , "ht", "ht.r250", "ht.r1k", "cov2_4.r250", "cov2_4.r1k", "cov4_16", "cov4_16.r250", "cov4_16.r1k", "mTopo", "cut.r1k.pt", "insideHJA", "lg_DistStream", "lg_DistRoad", "lg_YrsDisturb", "l_p25", "l_rumple")
## two points not covered by tpi and tri
indNA <- complete.cases(env.vars[,vars])
sum(indNA)
env.vars <- env.vars[indNA,]
otu.pa.csv <- otu.pa.csv[indNA,]
otu.qp.csv <- otu.qp.csv[indNA,]
rm(indNA)
colnames(env.vars)
## Save model data
save(otu.pa.csv, otu.qp.csv, otuenv, env.vars,
k, minocc, noSteps, vars, varsName, abund, device, iter, sampling,
file = file.path(resFolder, "modelData.rdata"))
`s-jSDM_tuning_model_vars3_5CV_5_tr_2000_pa` <- readRDS("J:/UEA/gitHRepos/HJA_analyses_Kelpie/Hmsc_CD/oregon_ada/code_sJSDM/r20210319a/results/s-jSDM_tuning_model_vars3_5CV_5_tr_2000_pa.rds")
`s-jSDM_tuning_model_vars3_5CV_5_tr_2000_qp` <- readRDS("J:/UEA/gitHRepos/HJA_analyses_Kelpie/Hmsc_CD/oregon_ada/code_sJSDM/r20210319b/results/s-jSDM_tuning_model_vars3_5CV_5_tr_2000_qp.rds")
load("J:/UEA/gitHRepos/HJA_analyses_Kelpie/Hmsc_CD/oregon_ada/code_sJSDM/r20210319b/results/modelData.rdata")
resFolder <-"code_sjSDM/r20210319b/results"
if(!dir.exists(resFolder)) dir.create(resFolder, recursive = TRUE)
## Updated to new vars, also changes to elevation_m, canopy_height_m  to _f.
# # model settings:
abund <- "qp"
spChoose <- "M1"
device <- "gpu"
iter <- 150L
sampling <- 5000L
## Number of samples from tuning grid - random search
noSteps <- 2000
# no of CV folds
k <- 5
# timings...
# models take approx to 0.28 mins run (Run time 00:36:11 for 125 models)
# noSteps * k * 0.28/60
noSteps * k
# Storage
# About ~600k per model .rds -- in GB
# noSteps * k * 600  / 1048576
# for testing on cpu
# device <- "cpu"
# iter <- 10L
# sampling <- 100L
# noSteps <- 5
# k <- 3
### 1. Get data from github #####
samtoolsfilter <- "F2308" # F2308 filter only
samtoolsqual <- "q48"
minimaprundate <- 20200929
kelpierundate <- 20200927
primer <- "BF3BR2"
gitHub <- "https://raw.githubusercontent.com/dougwyu/HJA_analyses_Kelpie/master/Kelpie_maps"
outputidxstatstabulatefolder <- paste0("outputs_minimap2_",
minimaprundate,"_",
samtoolsfilter,"_",
samtoolsqual,
"_kelpie",
kelpierundate,
"_",
primer,
"_vsearch97")
datFile <- paste0("sample_by_species_table_",
samtoolsfilter,
"_minimap2_",
minimaprundate,
"_kelpie",
kelpierundate,
"_FSL_qp.csv")
# file path:
fn <- file.path(gitHub, outputidxstatstabulatefolder, datFile)
# what file am i using?
basename(fn)
# when was it modified? - only if stored locally.
file.mtime(fn)
# read complete data set
otuenv <- read.csv(fn, stringsAsFactors = FALSE, na.strings = "NA")
# keep OTUs with >= minocc incidences AND with presnece at both M1 or M2
minocc <- 6 # set to high number (e.g. 20) for testing
## get Species columns by M1 and M2, with minocc calculated per trap
spM <- otuenv %>%
dplyr::filter(period == "S1") %>%
dplyr::select(SiteName, trap, contains("__")) %>%
tidyr::pivot_longer(cols = contains("__"), names_to = "OTU", values_drop_na = FALSE) %>%
mutate(value = value>0) %>% # change to PA
group_by(OTU, trap) %>%
summarise(nSites = sum(value, na.rm = T)) %>% # Number of sites at which present
filter(nSites >= minocc) %>% # filter by minocc
ungroup() %>%
tidyr::pivot_wider(names_from = trap, values_from = nSites, values_fn = function(x) sum(x)>0) %>%
filter(M1) %>% # CHOOOSE HERE FOR SINGLE. OR SHARED TRAP SPECIES GFROUP: filter(M1 & M2)
select(OTU)
# filter species here to those in sp.M1m2$OTU - already filtered for minocc
otu.qp.csv <- otuenv %>%
dplyr::filter(period == "S1" & trap == "M1") %>%
dplyr::select(spM$OTU) ##
# convert to presence/absence data
otu.pa.csv <- otu.qp.csv
otu.pa.csv[otu.pa.csv > 0] <- 1
min(colSums(otu.pa.csv)) >= minocc # should be TRUE
# clean up
rm(datFile, gitHub, kelpierundate, minimaprundate, outputidxstatstabulatefolder, primer, samtoolsfilter, samtoolsqual, fn, spM)
# remove OTUs, XY, and normalised NDVI and EVI
# average, optionally log, select, and scale env covariates
env.vars <- otuenv %>%
dplyr::filter(period == "S1" & trap == "M1") %>%
dplyr::select(!contains("__"), UTM_E, UTM_N, -starts_with("nor")) %>%
mutate(uniqueID = paste(SiteName, trap, period, sep = "_"),
elevation_m = elevation_f * 0.3048, ## convert to metres
canopyHeight_m = canopyHeight_f * 0.3048,
B1_median = apply(across(starts_with("B1_")), 1, median),
B2_median = apply(across(starts_with("B2_")), 1, median),
B3_median = apply(across(starts_with("B3_")), 1, median),
B4_median = apply(across(starts_with("B4_")), 1, median),
B5_median = apply(across(starts_with("B5_")), 1, median),
B6_median = apply(across(starts_with("B6_")), 1, median),
B7_median = apply(across(starts_with("B7_")), 1, median),
B10_median = apply(across(starts_with("B10_")), 1, median),
B11_median = apply(across(starts_with("B11_")), 1, median),
lg_DistStream = log(distToStream_m + 0.001),
lg_DistRoad = log(distToRoad_m + 0.001),
lg_YrsDisturb = log(YrsSinceDist + 0.001),
lg_cover2m_max = log(l_Cover_2m_max + 0.001),
lg_cover2m_4m = log(l_Cover_2m_4m + 0.001),
lg_cover4m_16m = log(l_Cover_4m_16m + 0.001)) %>%
mutate(
clearcut = factor(clearcut),
insideHJA = factor(insideHJA))
# str(env.vars)
# head(env.vars)
# load new variables
load("data/ann_topo.df")
sapply(ann.topo, function(x) sum(is.na(x)))
colnames(ann.topo)
##  merge with env.vars
env.vars <- dplyr::left_join(env.vars, ann.topo, by = "SiteName")
# summary(env.vars)
env.vars$tpi <- as.factor(env.vars$tpi)
# str(env.vars)
# old vars
# oldVars <- c("insideHJA", "elevation_f", "canopyHeight_f", "minT_annual", "precipitation_mm", "distToRoad_m", "distToStream_m", "YrsSinceDist", "B1_20180717", "B2_20180717", "B3_20180717", "B4_20180717", "B5_20180717", "B6_20180717", "B7_20180717", "B10_20180717", "B11_20180717", "NDVI_20180717", "EVI_20180717", "B_20180717", "G_20180717", "W_20180717", "l_Cover_2m_max", "l_Cover_2m_4m", "l_Cover_4m_16m", "l_p25", "l_p95", "l_rumple")
#
# # new vars
# newvars <- c("be10", "tri", "slope", "Nss", "Ess", "ht", "ht.r250", "ht.r500", "ht.r1k", "cov2_4", "cov2_4.r250", "cov2_4.r500", "cov2_4.r1k", "cov4_16", "cov4_16.r250", "cov4_16.r500", "cov4_16.r1k", "be500", "mTopo", "cut.r1k.pt", "insideHJA", "minT_annual", "maxT_annual", "precipitation_mm", "lg_DistStream", "lg_DistRoad", "lg_YrsDisturb", "B1_20180717", "B2_20180717", "B3_20180717", "B4_20180717", "B5_20180717", "B6_20180717", "B7_20180717", "B10_20180717", "B11_20180717", "NDVI_20180717", "EVI_20180717", "B_20180717", "G_20180717", "W_20180717", "l_p25", "l_rumple")
varsName <- "vars3"
vars <- c("be10", "slope", "tri", "Nss", "Ess","ndmi_stdDev", "ndvi_p5", "ndvi_p50", "ndvi_p95", "ndmi_p5", "ndmi_p50", "ndmi_p95", "savi_p50", "LC08_045029_20180726_B1", "LC08_045029_20180726_B3", "LC08_045029_20180726_B4", "LC08_045029_20180726_B5", "LC08_045029_20180726_B7", "LC08_045029_20180726_B10", "ndmi_stdDev_100m", "ndvi_p5_100m", "ndvi_p50_100m", "ndvi_p95_100m", "ndmi_p5_100m", "ndmi_p50_100m", "ndmi_p95_100m", "savi_p50_100m", "LC08_045029_20180726_B1_100m", "LC08_045029_20180726_B3_100m", "LC08_045029_20180726_B4_100m", "LC08_045029_20180726_B5_100m", "LC08_045029_20180726_B7_100m", "LC08_045029_20180726_B10_100m", "tpi250",  "tpi500", "tpi1k" , "ht", "ht.r250", "ht.r1k", "cov2_4.r250", "cov2_4.r1k", "cov4_16", "cov4_16.r250", "cov4_16.r1k", "mTopo", "cut.r1k.pt", "insideHJA", "lg_DistStream", "lg_DistRoad", "lg_YrsDisturb", "l_p25", "l_rumple")
## two points not covered by tpi and tri
indNA <- complete.cases(env.vars[,vars])
sum(indNA)
env.vars <- env.vars[indNA,]
otu.pa.csv <- otu.pa.csv[indNA,]
otu.qp.csv <- otu.qp.csv[indNA,]
rm(indNA)
# colnames(env.vars)
## Save model data
save(otu.pa.csv, otu.qp.csv, otuenv, env.vars,
k, minocc, noSteps, vars, varsName, abund, device, iter, sampling,
file = file.path(resFolder, "modelData.rdata"))
load("J:/UEA/gitHRepos/HJA_analyses_Kelpie/Hmsc_CD/oregon_ada/code_sJSDM/r20210319a/results/modelData.rdata")
# [1] ‘0.1.3.9000’
getwd() # always run sub from oregon_ada
library(dplyr)
resFolder <-"code_sjSDM/r20210319a/results"
if(!dir.exists(resFolder)) dir.create(resFolder, recursive = TRUE)
## Updated to new vars, also changes to elevation_m, canopy_height_m  to _f.
# # model settings:
abund <- "pa"
spChoose <- "M1"
device <- "gpu"
iter <- 150L
sampling <- 5000L
## Number of samples from tuning grid - random search
noSteps <- 2000
# no of CV folds
k <- 5
# timings...
# models take approx to 0.28 mins run (Run time 00:36:11 for 125 models)
# noSteps * k * 0.28/60
noSteps * k
# Storage
# About ~600k per model .rds -- in GB
# noSteps * k * 600  / 1048576
# for testing on cpu
# device <- "cpu"
# iter <- 10L
# sampling <- 100L
# noSteps <- 5
# k <- 3
### 1. Get data from github #####
samtoolsfilter <- "F2308" # F2308 filter only
samtoolsqual <- "q48"
minimaprundate <- 20200929
kelpierundate <- 20200927
primer <- "BF3BR2"
gitHub <- "https://raw.githubusercontent.com/dougwyu/HJA_analyses_Kelpie/master/Kelpie_maps"
outputidxstatstabulatefolder <- paste0("outputs_minimap2_",
minimaprundate,"_",
samtoolsfilter,"_",
samtoolsqual,
"_kelpie",
kelpierundate,
"_",
primer,
"_vsearch97")
datFile <- paste0("sample_by_species_table_",
samtoolsfilter,
"_minimap2_",
minimaprundate,
"_kelpie",
kelpierundate,
"_FSL_qp.csv")
# file path:
fn <- file.path(gitHub, outputidxstatstabulatefolder, datFile)
# what file am i using?
basename(fn)
# when was it modified? - only if stored locally.
file.mtime(fn)
# read complete data set
otuenv <- read.csv(fn, stringsAsFactors = FALSE, na.strings = "NA")
# keep OTUs with >= minocc incidences AND with presnece at both M1 or M2
minocc <- 6 # set to high number (e.g. 20) for testing
## get Species columns by M1 and M2, with minocc calculated per trap
spM <- otuenv %>%
dplyr::filter(period == "S1") %>%
dplyr::select(SiteName, trap, contains("__")) %>%
tidyr::pivot_longer(cols = contains("__"), names_to = "OTU", values_drop_na = FALSE) %>%
mutate(value = value>0) %>% # change to PA
group_by(OTU, trap) %>%
summarise(nSites = sum(value, na.rm = T)) %>% # Number of sites at which present
filter(nSites >= minocc) %>% # filter by minocc
ungroup() %>%
tidyr::pivot_wider(names_from = trap, values_from = nSites, values_fn = function(x) sum(x)>0) %>%
filter(M1) %>% # CHOOOSE HERE FOR SINGLE. OR SHARED TRAP SPECIES GFROUP: filter(M1 & M2)
select(OTU)
# filter species here to those in sp.M1m2$OTU - already filtered for minocc
otu.qp.csv <- otuenv %>%
dplyr::filter(period == "S1" & trap == "M1") %>%
dplyr::select(spM$OTU) ##
# convert to presence/absence data
otu.pa.csv <- otu.qp.csv
otu.pa.csv[otu.pa.csv > 0] <- 1
min(colSums(otu.pa.csv)) >= minocc # should be TRUE
# clean up
rm(datFile, gitHub, kelpierundate, minimaprundate, outputidxstatstabulatefolder, primer, samtoolsfilter, samtoolsqual, fn, spM)
# remove OTUs, XY, and normalised NDVI and EVI
# average, optionally log, select, and scale env covariates
env.vars <- otuenv %>%
dplyr::filter(period == "S1" & trap == "M1") %>%
dplyr::select(!contains("__"), UTM_E, UTM_N, -starts_with("nor")) %>%
mutate(uniqueID = paste(SiteName, trap, period, sep = "_"),
elevation_m = elevation_f * 0.3048, ## convert to metres
canopyHeight_m = canopyHeight_f * 0.3048,
B1_median = apply(across(starts_with("B1_")), 1, median),
B2_median = apply(across(starts_with("B2_")), 1, median),
B3_median = apply(across(starts_with("B3_")), 1, median),
B4_median = apply(across(starts_with("B4_")), 1, median),
B5_median = apply(across(starts_with("B5_")), 1, median),
B6_median = apply(across(starts_with("B6_")), 1, median),
B7_median = apply(across(starts_with("B7_")), 1, median),
B10_median = apply(across(starts_with("B10_")), 1, median),
B11_median = apply(across(starts_with("B11_")), 1, median),
lg_DistStream = log(distToStream_m + 0.001),
lg_DistRoad = log(distToRoad_m + 0.001),
lg_YrsDisturb = log(YrsSinceDist + 0.001),
lg_cover2m_max = log(l_Cover_2m_max + 0.001),
lg_cover2m_4m = log(l_Cover_2m_4m + 0.001),
lg_cover4m_16m = log(l_Cover_4m_16m + 0.001)) %>%
mutate(
clearcut = factor(clearcut),
insideHJA = factor(insideHJA))
# str(env.vars)
# head(env.vars)
# load new variables
load("data/ann_topo.df")
sapply(ann.topo, function(x) sum(is.na(x)))
colnames(ann.topo)
##  merge with env.vars
env.vars <- dplyr::left_join(env.vars, ann.topo, by = "SiteName")
# summary(env.vars)
env.vars$tpi <- as.factor(env.vars$tpi)
# str(env.vars)
# old vars
# oldVars <- c("insideHJA", "elevation_f", "canopyHeight_f", "minT_annual", "precipitation_mm", "distToRoad_m", "distToStream_m", "YrsSinceDist", "B1_20180717", "B2_20180717", "B3_20180717", "B4_20180717", "B5_20180717", "B6_20180717", "B7_20180717", "B10_20180717", "B11_20180717", "NDVI_20180717", "EVI_20180717", "B_20180717", "G_20180717", "W_20180717", "l_Cover_2m_max", "l_Cover_2m_4m", "l_Cover_4m_16m", "l_p25", "l_p95", "l_rumple")
#
# # new vars
# newvars <- c("be10", "tri", "slope", "Nss", "Ess", "ht", "ht.r250", "ht.r500", "ht.r1k", "cov2_4", "cov2_4.r250", "cov2_4.r500", "cov2_4.r1k", "cov4_16", "cov4_16.r250", "cov4_16.r500", "cov4_16.r1k", "be500", "mTopo", "cut.r1k.pt", "insideHJA", "minT_annual", "maxT_annual", "precipitation_mm", "lg_DistStream", "lg_DistRoad", "lg_YrsDisturb", "B1_20180717", "B2_20180717", "B3_20180717", "B4_20180717", "B5_20180717", "B6_20180717", "B7_20180717", "B10_20180717", "B11_20180717", "NDVI_20180717", "EVI_20180717", "B_20180717", "G_20180717", "W_20180717", "l_p25", "l_rumple")
varsName <- "vars3"
vars <- c("be10", "slope", "tri", "Nss", "Ess","ndmi_stdDev", "ndvi_p5", "ndvi_p50", "ndvi_p95", "ndmi_p5", "ndmi_p50", "ndmi_p95", "savi_p50", "LC08_045029_20180726_B1", "LC08_045029_20180726_B3", "LC08_045029_20180726_B4", "LC08_045029_20180726_B5", "LC08_045029_20180726_B7", "LC08_045029_20180726_B10", "ndmi_stdDev_100m", "ndvi_p5_100m", "ndvi_p50_100m", "ndvi_p95_100m", "ndmi_p5_100m", "ndmi_p50_100m", "ndmi_p95_100m", "savi_p50_100m", "LC08_045029_20180726_B1_100m", "LC08_045029_20180726_B3_100m", "LC08_045029_20180726_B4_100m", "LC08_045029_20180726_B5_100m", "LC08_045029_20180726_B7_100m", "LC08_045029_20180726_B10_100m", "tpi250",  "tpi500", "tpi1k" , "ht", "ht.r250", "ht.r1k", "cov2_4.r250", "cov2_4.r1k", "cov4_16", "cov4_16.r250", "cov4_16.r1k", "mTopo", "cut.r1k.pt", "insideHJA", "lg_DistStream", "lg_DistRoad", "lg_YrsDisturb", "l_p25", "l_rumple")
## two points not covered by tpi and tri
indNA <- complete.cases(env.vars[,vars])
sum(indNA)
env.vars <- env.vars[indNA,]
otu.pa.csv <- otu.pa.csv[indNA,]
otu.qp.csv <- otu.qp.csv[indNA,]
rm(indNA)
colnames(env.vars)
## Save model data
save(otu.pa.csv, otu.qp.csv, otuenv, env.vars,
k, minocc, noSteps, vars, varsName, abund, device, iter, sampling,
file = file.path(resFolder, "modelData.rdata"))
