summarise(occ = sum(value, na.rm = T)) %>%
filter(occ >= minocc)
sp.chk
minocc <- 6 # set to high number (e.g. 20) for testing
otu.qp.csv <- otuenv %>%
dplyr::filter(period == "S1")%>%
dplyr::select(contains("__")) ## file above is already qp
otu.qp.csv <- otu.qp.csv[ , colSums(otu.qp.csv > 0) >= minocc]
sp.chk <- otuenv %>%
dplyr::filter(period == "S1")%>%
dplyr::select(SiteName, trap, contains("__")) %>%
tidyr::pivot_longer(cols = contains("__"), names_to = "OTU") %>%
mutate(value = value>0) %>% # change to PA
group_by(OTU, trap) %>%
summarise(occ = sum(value, na.rm = T))
sp.chk
sp.chk <- otuenv %>%
dplyr::filter(period == "S1")%>%
dplyr::select(SiteName, trap, contains("__")) %>%
tidyr::pivot_longer(cols = contains("__"), names_to = "OTU") %>%
mutate(value = value>0) %>% # change to PA
group_by(OTU, trap) %>%
summarise(nSites = sum(value, na.rm = T))
sp.chk
sp.chk <- otuenv %>%
dplyr::filter(period == "S1")%>%
dplyr::select(SiteName, trap, contains("__")) %>%
tidyr::pivot_longer(cols = contains("__"), names_to = "OTU") %>%
mutate(value = value>0) %>% # change to PA
group_by(OTU, trap) %>%
summarise(nSites = sum(value, na.rm = T)) %>% # Number of sites at which present
filter(nSites >= minocc) %>% # filter by minocc
ungroup()
sp.chk
sp.chk <- otuenv %>%
dplyr::filter(period == "S1")%>%
dplyr::select(SiteName, trap, contains("__")) %>%
tidyr::pivot_longer(cols = contains("__"), names_to = "OTU") %>%
mutate(value = value>0) %>% # change to PA
group_by(OTU, trap) %>%
summarise(nSites = sum(value, na.rm = T)) %>% # Number of sites at which present
filter(nSites >= minocc) %>% # filter by minocc
ungroup() %>%
tidyr::pivot_wider(names_from = trap, values_from = nSites, values_fn = function(x) sum(x)>0)
sp.chk
sp.chk <- otuenv %>%
dplyr::filter(period == "S1")%>%
dplyr::select(SiteName, trap, contains("__")) %>%
tidyr::pivot_longer(cols = contains("__"), names_to = "OTU") %>%
mutate(value = value>0) %>% # change to PA
group_by(OTU, trap) %>%
summarise(nSites = sum(value, na.rm = T)) %>% # Number of sites at which present
filter(nSites >= minocc)
otu.qp.csv <- otuenv %>%
dplyr::filter(period == "S1")%>%
dplyr::select(contains("__")) ## file above is already qp
otu.qp.csv <- otu.qp.csv[ , colSums(otu.qp.csv > 0) >= minocc]
otus <- colnames(otu.qp.csv)
source("https://raw.githubusercontent.com/Cdevenish/R-Material/master/Functions/w.xls.r")
w.xls(otus)
sp.chk <- otuenv %>%
dplyr::filter(period == "S1")%>%
dplyr::select(SiteName, trap, contains("__")) %>%
tidyr::pivot_longer(cols = contains("__"), names_to = "OTU") %>%
mutate(value = value>0) %>% # change to PA
group_by(OTU, trap) %>%
summarise(nSites = sum(value, na.rm = T))
sp.chk
rm(p.chk)
otu.qp.csv <- otuenv %>%
dplyr::filter(period == "S1" & trap == "M1")%>%
dplyr::select(contains("__")) ## file above is already qp
otu.qp.csv <- otu.qp.csv[ , colSums(otu.qp.csv > 0) >= minocc]
otu.qp.csv <- otuenv %>%
dplyr::filter(period == "S1" & trap == "M1")%>%
dplyr::select(contains("__")) ## file above is already qp
otu.qp.csv <- otuenv %>%
dplyr::filter(period == "S1")%>%
dplyr::select(contains("__")) ## file above is already qp
otu.qp.csv <- otuenv %>%
dplyr::filter(period == "S1" & trap == "M1")%>%
dplyr::select(contains("__")) ## file above is already qp
colSums(otu.qp.csv > 0)
head(colSums(otu.qp.csv > 0))
sp.chk
sp.chk <- otuenv %>%
dplyr::filter(period == "S1")%>%
dplyr::select(SiteName, trap, contains("__")) %>%
tidyr::pivot_longer(cols = contains("__"), names_to = "OTU")
sp.chk
1210*94*2
1210*94
1210*89*2
1210*89
otu.qp.csv <- otuenv %>%
dplyr::filter(period == "S1")%>%
dplyr::select(contains("__")) ## file above is already qp
otu.qp.csv <- otuenv %>%
dplyr::filter(period == "S1")%>%
dplyr::select(contains("__")) ## file above is already qp
length(uniqueSites$SiteName)
1210*33 + 1210*88
1210*88 + 1210*33
sp.chk <- otuenv %>%
dplyr::filter(period == "S1")%>%
dplyr::select(SiteName, trap, contains("__")) %>%
tidyr::pivot_longer(cols = contains("__"), names_to = "OTU", values_drop_na = FALSE) %>%
mutate(value = value>0)
sp.chk
sp.chk <- otuenv %>%
dplyr::filter(period == "S1")%>%
dplyr::select(SiteName, trap, contains("__")) %>%
tidyr::pivot_longer(cols = contains("__"), names_to = "OTU", values_drop_na = FALSE) %>%
mutate(value = value>0) %>% # change to PA
group_by(OTU, trap) %>%
summarise(nSites = sum(value, na.rm = T))
sp.chk
max(sp.chk$nSites)
max(colSums(otu.qp.csv > 0))
otu.qp.csv <- otuenv %>%
dplyr::filter(period == "S1")%>%
dplyr::select(contains("__")) ## file above is already qp
otu.qp.csv <- otuenv %>%
dplyr::filter(period == "S1" & trap == "M1")%>%
dplyr::select(contains("__")) ## file above is already qp
otu.qp.csv <- otu.qp.csv[ , colSums(otu.qp.csv > 0) >= minocc]
otus <- colnames(otu.qp.csv)
head(colSums(otu.qp.csv > 0))
max(colSums(otu.qp.csv > 0))
sp.chk <- otuenv %>%
dplyr::filter(period == "S1")%>%
dplyr::select(SiteName, trap, contains("__")) %>%
tidyr::pivot_longer(cols = contains("__"), names_to = "OTU", values_drop_na = FALSE) %>%
mutate(value = value>0) %>% # change to PA
group_by(OTU, trap) %>%
summarise(nSites = sum(value, na.rm = T)) %>% # Number of sites at which present
filter(nSites >= minocc)
sp.chk
sp.chk <- otuenv %>%
dplyr::filter(period == "S1")%>%
dplyr::select(SiteName, trap, contains("__")) %>%
tidyr::pivot_longer(cols = contains("__"), names_to = "OTU", values_drop_na = FALSE) %>%
mutate(value = value>0) %>% # change to PA
group_by(OTU, trap) %>%
summarise(nSites = sum(value, na.rm = T))
1210*2
sp.chk <- otuenv %>%
dplyr::filter(period == "S1")%>%
dplyr::select(SiteName, trap, contains("__")) %>%
tidyr::pivot_longer(cols = contains("__"), names_to = "OTU", values_drop_na = FALSE) %>%
mutate(value = value>0) %>% # change to PA
group_by(OTU, trap) %>%
summarise(nSites = sum(value, na.rm = T)) %>% # Number of sites at which present
filter(nSites >= minocc)
sp.chk <- otuenv %>%
dplyr::filter(period == "S1")%>%
dplyr::select(SiteName, trap, contains("__")) %>%
tidyr::pivot_longer(cols = contains("__"), names_to = "OTU", values_drop_na = FALSE) %>%
mutate(value = value>0) %>% # change to PA
group_by(OTU, trap) %>%
summarise(nSites = sum(value, na.rm = T)) %>% # Number of sites at which present
filter(nSites >= minocc) %>% # filter by minocc
ungroup() %>%
tidyr::pivot_wider(names_from = trap, values_from = nSites, values_fn = function(x) sum(x)>0)
sp.chk <- otuenv %>%
dplyr::filter(period == "S1")%>%
dplyr::select(SiteName, trap, contains("__")) %>%
tidyr::pivot_longer(cols = contains("__"), names_to = "OTU", values_drop_na = FALSE) %>%
mutate(value = value>0) %>% # change to PA
group_by(OTU, trap) %>%
summarise(nSites = sum(value, na.rm = T)) %>% # Number of sites at which present
filter(nSites >= minocc)
sp.chk <- otuenv %>%
dplyr::filter(period == "S1")%>%
dplyr::select(SiteName, trap, contains("__")) %>%
tidyr::pivot_longer(cols = contains("__"), names_to = "OTU", values_drop_na = FALSE) %>%
mutate(value = value>0) %>% # change to PA
group_by(OTU, trap) %>%
summarise(nSites = sum(value, na.rm = T))
sp.chk <- otuenv %>%
dplyr::filter(period == "S1")%>%
dplyr::select(SiteName, trap, contains("__")) %>%
tidyr::pivot_longer(cols = contains("__"), names_to = "OTU", values_drop_na = FALSE) %>%
mutate(value = value>0)
1210*88 + 1210*33
sp.chk <- otuenv %>%
dplyr::filter(period == "S1")%>%
dplyr::select(SiteName, trap, contains("__")) %>%
tidyr::pivot_longer(cols = contains("__"), names_to = "OTU", values_drop_na = FALSE) %>%
mutate(value = value>0) %>% # change to PA
group_by(OTU, trap) %>%
summarise(nSites = sum(value, na.rm = T))
1210*2
sp.chk <- otuenv %>%
dplyr::filter(period == "S1")%>%
dplyr::select(SiteName, trap, contains("__")) %>%
tidyr::pivot_longer(cols = contains("__"), names_to = "OTU", values_drop_na = FALSE) %>%
mutate(value = value>0) %>% # change to PA
group_by(OTU, trap) %>%
summarise(nSites = sum(value, na.rm = T)) %>% # Number of sites at which present
filter(nSites >= minocc)
noSteps <- 1000
k <- 10
noSteps * k
noSteps * k * 0.28/60
format("25/02/2021 20:56:09", "%m/%d/%Y %H:%M:%S")
format("25/02/2021 20:56:09", format = "%m/%d/%Y %H:%M:%S")
Sys.time()
Sys.time() - format("25/02/2021 20:56:09", format = "%m/%d/%Y %H:%M:%S")
diff(Sys.time(), format("25/02/2021 20:56:09", format = "%m/%d/%Y %H:%M:%S"))
diff(Sys.time(), strptime("25/02/2021 20:56:09", format = "%m/%d/%Y %H:%M:%S"))
strptime("25/02/2021 20:56:09", format = "%m/%d/%Y %H:%M:%S")
diff(Sys.time(), strptime("25/02/2021 20:56:09", format = "%m/%d/%Y %H:%M:%S", tz = "GMT"))
strptime("25/02/2021 20:56:09", format = "%m/%d/%Y %H:%M:%S", tz = "GMT")
strptime("25/02/2021 20:56:09")
strptime("25/02/2021 20:56:09", format = "%m/%d/%Y %H:%M:%S", tz = "GMT")
strptime("25/02/2021 20:56:09", format = "%d/%m/%Y %H:%M:%S", tz = "GMT")
diff(Sys.time(),
strptime("25/02/2021 20:56:09", format = "%d/%m/%Y %H:%M:%S", tz = "GMT")
)
format(Sys.time())
diff(format(Sys.time()),
strptime("25/02/2021 20:56:09", format = "%d/%m/%Y %H:%M:%S", tz = "GMT")
)
Sys.time()
strptime(Sys.time(), format = "%Y-%m-%d %H:%M:%S")
diff(strptime(Sys.time(), format = "%Y-%m-%d %H:%M:%S"),
strptime("25/02/2021 20:56:09", format = "%d/%m/%Y %H:%M:%S", tz = "GMT")
)
strptime(Sys.time(), format = "%Y-%m-%d %H:%M:%S") - strptime("25/02/2021 20:56:09", format = "%d/%m/%Y %H:%M:%S", tz = "GMT")
difftime(strptime(Sys.time(), format = "%Y-%m-%d %H:%M:%S"),
strptime("25/02/2021 20:56:09", format = "%d/%m/%Y %H:%M:%S", tz = "GMT"),
"hours")
difftime(strptime(Sys.time(), format = "%Y-%m-%d %H:%M:%S"),
strptime("25/02/2021 20:56:09", format = "%d/%m/%Y %H:%M:%S", tz = "GMT"),
units = "hours")
6800 / 37
6800 / 37 *10000
10000/ (6800 / 37)
difftime(strptime(Sys.time(), format = "%Y-%m-%d %H:%M:%S"),
strptime("25/02/2021 20:56:09", format = "%d/%m/%Y %H:%M:%S", tz = "GMT"),
units = "minutes")
difftime(strptime(Sys.time(), format = "%Y-%m-%d %H:%M:%S"),
strptime("25/02/2021 20:56:09", format = "%d/%m/%Y %H:%M:%S", tz = "GMT"),
units = "mins")
ms <- difftime(strptime(Sys.time(), format = "%Y-%m-%d %H:%M:%S"),
strptime("25/02/2021 20:56:09", format = "%d/%m/%Y %H:%M:%S", tz = "GMT"),
units = "mins")
10000/ (6800 / ms)
10000/ (6800 / as.numeric(ms))
6800 / as.numeric(ms)
6873 / as.numeric(ms)
ms <- difftime(strptime(Sys.time(), format = "%Y-%m-%d %H:%M:%S"),
strptime("27/02/2021 11:39:08", format = "%d/%m/%Y %H:%M:%S", tz = "GMT"),
units = "mins")
ms
880/as.numeric(ms)
4*60*3
120/3
abund <- "pa"
device <- "gpu"
iter <- 150L
sampling <- 5000L
## Number of samples from tuning grid - random search
noSteps <- 1000
# no of CV folds
k <- 10
i= 9
j = 1
resFolder <-"code_sjSDM/r20210225a/results"
file.path(resFolder,paste0("s-jSDM_tuning_model_", k, "CV_",
i, "_tr_", j, "_", abund, ".rds"))
200/3
2000/5
400/60
ms <- difftime(strptime(Sys.time(), format = "%Y-%m-%d %H:%M:%S"),
strptime("27/02/2021 17:05:20", format = "%d/%m/%Y %H:%M:%S", tz = "GMT"),
units = "mins")
81/as.numeric(ms)
2000/3/60
resFolder <-"code_sjSDM/r20210225a/results"
abund <- "pa"
device <- "gpu"
iter <- 150L
sampling <- 5000L
# no of CV folds
k <- 10
## Number of samples from tuning grid - random search
noSteps <- 1000 # for results filename
samtoolsfilter <- "F2308" # F2308 filter only
samtoolsqual <- "q48"
minimaprundate <- 20200929
kelpierundate <- 20200927
primer <- "BF3BR2"
gitHub <- "https://raw.githubusercontent.com/dougwyu/HJA_analyses_Kelpie/master/Kelpie_maps"
outputidxstatstabulatefolder <- paste0("outputs_minimap2_",
minimaprundate,"_",
samtoolsfilter,"_",
samtoolsqual,
"_kelpie",
kelpierundate,
"_",
primer,
"_vsearch97")
datFile <- paste0("sample_by_species_table_",
samtoolsfilter,
"_minimap2_",
minimaprundate,
"_kelpie",
kelpierundate,
"_FSL_qp.csv")
# file path:
fn <- file.path(gitHub, outputidxstatstabulatefolder, datFile)
# what file am i using?
basename(fn)
# when was it modified? - only if stored locally.
file.mtime(fn)
# read complete data set
otuenv <- read.csv(fn, stringsAsFactors = FALSE, na.strings = "NA")
# Filter M1S1
trap <- "M1"
period <- "S1"
otuenv <- otuenv %>%
dplyr::filter(trap == trap[[1]] & period == period[[1]])
# clean up
rm(datFile, gitHub, kelpierundate, minimaprundate, outputidxstatstabulatefolder, period, primer, samtoolsfilter, samtoolsqual, trap, fn)
# keep OTUs with >=5 incidences
minocc <- 6 # set to high number (e.g. 20) for testing
otu.qp.csv <- otuenv %>% dplyr::select(contains("__")) ## file above is already qp
otu.qp.csv <- otu.qp.csv[ , colSums(otu.qp.csv > 0) >= minocc]
# convert to presence/absence data
otu.pa.csv <- otu.qp.csv
otu.pa.csv[otu.pa.csv > 0] <- 1
min(colSums(otu.pa.csv)) == minocc # should be TRUE
# rm(minocc)
# remove OTUs, XY, and normalised NDVI and EVI
# average, optionally log, select, and scale env covariates
env.vars <- otuenv %>%
dplyr::select(!contains("__"), UTM_E, UTM_N, -starts_with("nor")) %>%
mutate(uniqueID = paste(SiteName, trap, period, sep = "_"),
elevation_m = elevation_f * 0.3048, ## convert to metres
canopyHeight_m = canopyHeight_f * 0.3048,
B1_median = apply(across(starts_with("B1_")), 1, median),
B2_median = apply(across(starts_with("B2_")), 1, median),
B3_median = apply(across(starts_with("B3_")), 1, median),
B4_median = apply(across(starts_with("B4_")), 1, median),
B5_median = apply(across(starts_with("B5_")), 1, median),
B6_median = apply(across(starts_with("B6_")), 1, median),
B7_median = apply(across(starts_with("B7_")), 1, median),
B10_median = apply(across(starts_with("B10_")), 1, median),
B11_median = apply(across(starts_with("B11_")), 1, median),
lg_DistStream = log(distToStream_m + 0.001),
lg_DistRoad = log(distToRoad_m + 0.001),
lg_YrsDisturb = log(YrsSinceDist + 0.001),
lg_cover2m_max = log(l_Cover_2m_max + 0.001),
lg_cover2m_4m = log(l_Cover_2m_4m + 0.001),
lg_cover4m_16m = log(l_Cover_4m_16m + 0.001)) %>%
# dplyr::select(uniqueID, clearcut,insideHJA,oldGrowthIndex, elevation_m, canopyHeight_m, precipitation_mm, minT_annual,
#               maxT_annual, mean.NDVI, mean.EVI, mean.green, mean.wet, mean.bright, l_p25, l_p95, l_rumple, B1_median,
#               B2_median,B3_median,B4_median,B5_median,B6_median,B7_median,B10_median,B11_median,lg_DistStream,
#               lg_DistRoad, lg_YrsDisturb, lg_cover2m_max, lg_cover2m_4m, lg_cover4m_16m, l_Cover_2m_4m,l_Cover_4m_16m,
#               be10, tri, slope, twi, Nss, Ess, ht, ht.r250, ht.r500, ht.r1k, cov2_4, cov2_4.r250, cov2_4.r500, cov2_4.r1k,
#               cov4_16, cov4_16.r250, cov4_16.r500, cov4_16.r1k, be500, mTopo, cut.r1k.pt,B1_20180717, B2_20180717,
#               B3_20180717, B4_20180717, B5_20180717, B6_20180717, B7_20180717, B10_20180717, B11_20180717, NDVI_20180717,
#               EVI_20180717, B_20180717, G_20180717, W_20180717) %>%
mutate(
#across(where(is.numeric), scale), # scale here # scale when defining models etc.
clearcut = factor(clearcut),
insideHJA = factor(insideHJA))
#dplyr::select(-uniqueID)
# str(env.vars)
# head(env.vars)
# old vars
oldVars <- c("insideHJA", "elevation_f", "canopyHeight_f", "minT_annual", "precipitation_mm", "distToRoad_m", "distToStream_m", "YrsSinceDist", "B1_20180717", "B2_20180717", "B3_20180717", "B4_20180717", "B5_20180717", "B6_20180717", "B7_20180717", "B10_20180717", "B11_20180717", "NDVI_20180717", "EVI_20180717", "B_20180717", "G_20180717", "W_20180717", "l_Cover_2m_max", "l_Cover_2m_4m", "l_Cover_4m_16m", "l_p25", "l_p95", "l_rumple")
# new vars
newvars <- c("be10", "tri", "slope", "Nss", "Ess", "ht", "ht.r250", "ht.r500", "ht.r1k", "cov2_4", "cov2_4.r250", "cov2_4.r500", "cov2_4.r1k", "cov4_16", "cov4_16.r250", "cov4_16.r500", "cov4_16.r1k", "be500", "mTopo", "cut.r1k.pt", "insideHJA", "minT_annual", "maxT_annual", "precipitation_mm", "lg_DistStream", "lg_DistRoad", "lg_YrsDisturb", "B1_20180717", "B2_20180717", "B3_20180717", "B4_20180717", "B5_20180717", "B6_20180717", "B7_20180717", "B10_20180717", "B11_20180717", "NDVI_20180717", "EVI_20180717", "B_20180717", "G_20180717", "W_20180717", "l_p25", "l_rumple")
### 2. Make testing and training k folds #####
# Make folds
set.seed(100)
# make fold ids, length == to data set nrow, sample to randomise order
fold.id <- sample(rep_len(1:k, length.out = nrow(otu.pa.csv)))
table(fold.id)
minocc <- 6 # set to high number (e.g. 20) for testing
otu.qp.csv <- otuenv %>% dplyr::select(contains("__")) ## file above is already qp
otu.qp.csv <- otu.qp.csv[ , colSums(otu.qp.csv > 0) >= minocc]
# convert to presence/absence data
otu.pa.csv <- otu.qp.csv
otu.pa.csv[otu.pa.csv > 0] <- 1
min(colSums(otu.pa.csv)) == minocc # should be TRUE
minocc <- 6 # set to high number (e.g. 20) for testing
trap <- "M1"
period <- "S1"
otuenv <- otuenv %>%
dplyr::filter(trap == trap[[1]] & period == period[[1]])
rm(datFile, gitHub, kelpierundate, minimaprundate, outputidxstatstabulatefolder, period, primer, samtoolsfilter, samtoolsqual, trap, fn)
setwd("J:/UEA/gitHRepos/HJA_analyses_Kelpie/Hmsc_CD/oregon_ada")
library(dplyr)
resFolder <-"code_sjSDM/r20210225a/results"
abund <- "pa"
device <- "gpu"
iter <- 150L
sampling <- 5000L
# no of CV folds
k <- 10
## Number of samples from tuning grid - random search
noSteps <- 1000 # for results filename
samtoolsfilter <- "F2308" # F2308 filter only
samtoolsqual <- "q48"
minimaprundate <- 20200929
kelpierundate <- 20200927
primer <- "BF3BR2"
gitHub <- "https://raw.githubusercontent.com/dougwyu/HJA_analyses_Kelpie/master/Kelpie_maps"
outputidxstatstabulatefolder <- paste0("outputs_minimap2_",
minimaprundate,"_",
samtoolsfilter,"_",
samtoolsqual,
"_kelpie",
kelpierundate,
"_",
primer,
"_vsearch97")
datFile <- paste0("sample_by_species_table_",
samtoolsfilter,
"_minimap2_",
minimaprundate,
"_kelpie",
kelpierundate,
"_FSL_qp.csv")
# file path:
fn <- file.path(gitHub, outputidxstatstabulatefolder, datFile)
# what file am i using?
basename(fn)
# when was it modified? - only if stored locally.
file.mtime(fn)
# read complete data set
otuenv <- read.csv(fn, stringsAsFactors = FALSE, na.strings = "NA")
# Filter M1S1
trap <- "M1"
period <- "S1"
otuenv <- otuenv %>%
dplyr::filter(trap == trap[[1]] & period == period[[1]])
# clean up
rm(datFile, gitHub, kelpierundate, minimaprundate, outputidxstatstabulatefolder, period, primer, samtoolsfilter, samtoolsqual, trap, fn)
minocc <- 6 # set to high number (e.g. 20) for testing
otu.qp.csv <- otuenv %>% dplyr::select(contains("__")) ## file above is already qp
otu.qp.csv <- otu.qp.csv[ , colSums(otu.qp.csv > 0) >= minocc]
# convert to presence/absence data
otu.pa.csv <- otu.qp.csv
otu.pa.csv[otu.pa.csv > 0] <- 1
min(colSums(otu.pa.csv)) == minocc # should be TRUE
# rm(minocc)
# remove OTUs, XY, and normalised NDVI and EVI
# average, optionally log, select, and scale env covariates
env.vars <- otuenv %>%
dplyr::select(!contains("__"), UTM_E, UTM_N, -starts_with("nor")) %>%
mutate(uniqueID = paste(SiteName, trap, period, sep = "_"),
elevation_m = elevation_f * 0.3048, ## convert to metres
canopyHeight_m = canopyHeight_f * 0.3048,
B1_median = apply(across(starts_with("B1_")), 1, median),
B2_median = apply(across(starts_with("B2_")), 1, median),
B3_median = apply(across(starts_with("B3_")), 1, median),
B4_median = apply(across(starts_with("B4_")), 1, median),
B5_median = apply(across(starts_with("B5_")), 1, median),
B6_median = apply(across(starts_with("B6_")), 1, median),
B7_median = apply(across(starts_with("B7_")), 1, median),
B10_median = apply(across(starts_with("B10_")), 1, median),
B11_median = apply(across(starts_with("B11_")), 1, median),
lg_DistStream = log(distToStream_m + 0.001),
lg_DistRoad = log(distToRoad_m + 0.001),
lg_YrsDisturb = log(YrsSinceDist + 0.001),
lg_cover2m_max = log(l_Cover_2m_max + 0.001),
lg_cover2m_4m = log(l_Cover_2m_4m + 0.001),
lg_cover4m_16m = log(l_Cover_4m_16m + 0.001)) %>%
# dplyr::select(uniqueID, clearcut,insideHJA,oldGrowthIndex, elevation_m, canopyHeight_m, precipitation_mm, minT_annual,
#               maxT_annual, mean.NDVI, mean.EVI, mean.green, mean.wet, mean.bright, l_p25, l_p95, l_rumple, B1_median,
#               B2_median,B3_median,B4_median,B5_median,B6_median,B7_median,B10_median,B11_median,lg_DistStream,
#               lg_DistRoad, lg_YrsDisturb, lg_cover2m_max, lg_cover2m_4m, lg_cover4m_16m, l_Cover_2m_4m,l_Cover_4m_16m,
#               be10, tri, slope, twi, Nss, Ess, ht, ht.r250, ht.r500, ht.r1k, cov2_4, cov2_4.r250, cov2_4.r500, cov2_4.r1k,
#               cov4_16, cov4_16.r250, cov4_16.r500, cov4_16.r1k, be500, mTopo, cut.r1k.pt,B1_20180717, B2_20180717,
#               B3_20180717, B4_20180717, B5_20180717, B6_20180717, B7_20180717, B10_20180717, B11_20180717, NDVI_20180717,
#               EVI_20180717, B_20180717, G_20180717, W_20180717) %>%
mutate(
#across(where(is.numeric), scale), # scale here # scale when defining models etc.
clearcut = factor(clearcut),
insideHJA = factor(insideHJA))
#dplyr::select(-uniqueID)
# str(env.vars)
# head(env.vars)
# old vars
oldVars <- c("insideHJA", "elevation_f", "canopyHeight_f", "minT_annual", "precipitation_mm", "distToRoad_m", "distToStream_m", "YrsSinceDist", "B1_20180717", "B2_20180717", "B3_20180717", "B4_20180717", "B5_20180717", "B6_20180717", "B7_20180717", "B10_20180717", "B11_20180717", "NDVI_20180717", "EVI_20180717", "B_20180717", "G_20180717", "W_20180717", "l_Cover_2m_max", "l_Cover_2m_4m", "l_Cover_4m_16m", "l_p25", "l_p95", "l_rumple")
# new vars
newvars <- c("be10", "tri", "slope", "Nss", "Ess", "ht", "ht.r250", "ht.r500", "ht.r1k", "cov2_4", "cov2_4.r250", "cov2_4.r500", "cov2_4.r1k", "cov4_16", "cov4_16.r250", "cov4_16.r500", "cov4_16.r1k", "be500", "mTopo", "cut.r1k.pt", "insideHJA", "minT_annual", "maxT_annual", "precipitation_mm", "lg_DistStream", "lg_DistRoad", "lg_YrsDisturb", "B1_20180717", "B2_20180717", "B3_20180717", "B4_20180717", "B5_20180717", "B6_20180717", "B7_20180717", "B10_20180717", "B11_20180717", "NDVI_20180717", "EVI_20180717", "B_20180717", "G_20180717", "W_20180717", "l_p25", "l_rumple")
set.seed(100)
# make fold ids, length == to data set nrow, sample to randomise order
fold.id <- sample(rep_len(1:k, length.out = nrow(otu.pa.csv)))
table(fold.id)
hidden <- list(c(50L,50L,10L), c(25L,25L,10L))
res <- read.csv(file.path(resFolder,paste0("manual_tuning_sjsdm_", k, "CV_M1S1_mean_AUC_",
abund,
"_min_",
minocc,
"_nSteps_",
noSteps,
".csv")))
head(res)
res.best <- res[which.max(res$AUC.test_mean),,drop = T]
res.best
load("J:/UEA/gitHRepos/HJA_analyses_Kelpie/Hmsc_CD/oregon_ada/code_sJSDM/r20210225a/results/sp_results.rdata")
head(eval.results)
eval.results
apply(eval.results, 2, mean)
eval.results
